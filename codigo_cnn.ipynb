{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b979188",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9524835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 13:38:40.519961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-01 13:38:40.630885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-01 13:38:40.630899: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-01 13:38:40.655470: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-01 13:38:41.182370: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-01 13:38:41.182459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-01 13:38:41.182466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow import keras\n",
    "\n",
    "#image manipulation packages\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "#Classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "sns.set()\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import Augmentor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "\n",
    "## RESNET50\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "### Efficient\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46707aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48a1908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(gpu_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21767c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearDataset(path_expertAnotations,path_partialImages, dest_path):\n",
    "    file = open(path_expertAnotations, 'r')\n",
    "    os.mkdir(dest_path+'/data')\n",
    "    os.mkdir(dest_path+'/data/01-Normal')\n",
    "    os.mkdir(dest_path+'/data/02-Tapered')\n",
    "    os.mkdir(dest_path+'/data/03-Pyriform')\n",
    "    os.mkdir(dest_path+'/data/04-Small')\n",
    "    os.mkdir(dest_path+'/data/05-Amorphous')\n",
    "\n",
    "    categorias = ['01-Normal', '02-Tapered', '03-Pyriform', '04-Small', '05-Amorphous']\n",
    "\n",
    "    for x in file:\n",
    "        # Se obtiene el nombre y clase desde el archivo txt\n",
    "        aux1 = x.split('\t')\n",
    "        clase = int(aux1[4].replace('\\n',''))\n",
    "        aux2 = aux1[0].replace('\\n','').split('-')\n",
    "        p = aux2[0]\n",
    "        pl = aux2[1]\n",
    "        aux3 = aux2[2].split('/')\n",
    "\n",
    "        n_sample = int(re.split('(\\d+)',aux3[0])[1])\n",
    "        n_sperm = int(re.split('(\\d+)',aux3[1])[1])\n",
    "        # Se conforma el directorio de la imagen a partir de la informacion anterior.\n",
    "        file = path_partialImages+'ch00_'+p+'-'+pl+'-sample'+str(n_sample)+'-sperm'+str(n_sperm)+'.tif'\n",
    "        # Se conforma el directorio donde se va a copiar la imagen\n",
    "        print(file)\n",
    "        aux = dest_path+'/data/'\n",
    "        if (clase == 0):\n",
    "            aux=aux+'01-Normal'\n",
    "        elif (clase == 1):\n",
    "            aux=aux+'02-Tapered'\n",
    "        elif (clase == 2):\n",
    "            aux=aux+'03-Pyriform'\n",
    "        elif (clase == 3):\n",
    "            aux=aux+'04-Small'\n",
    "        else:\n",
    "            aux=aux+'05-Amorphous'\n",
    "\n",
    "        # Se copia la imagen\n",
    "        shutil.copy(file,aux)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898ab7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed48408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileCount(folder):\n",
    "    \"count the number of files in a directory\"\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            count += 1\n",
    "        elif os.path.isdir(path):\n",
    "            count += fileCount(path)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearSubConjuntos( nombre_clase, dir_clase, dest_dir):\n",
    "    os.mkdir(dest_dir+\"/train/\"+nombre_clase)\n",
    "    os.mkdir(dest_dir+\"/test/\"+nombre_clase)\n",
    "    os.mkdir(dest_dir+\"/valid/\"+nombre_clase)\n",
    "    \n",
    "    lista = os.listdir(dir_clase)\n",
    "    cantidad_imagenes = len(lista)\n",
    "    contador = 0\n",
    "    while (cantidad_imagenes*0.2) > contador:\n",
    "        elemento = random.choice(lista)\n",
    "        lista.remove(elemento)\n",
    "        elemento = dir_clase+'/'+elemento\n",
    "        shutil.copy(elemento,dest_dir+\"/test/\"+nombre_clase)\n",
    "        contador = contador+1\n",
    "\n",
    "    contador = 0\n",
    "    while (cantidad_imagenes*0.2) > contador:\n",
    "        elemento = random.choice(lista)\n",
    "        lista.remove(elemento)\n",
    "        elemento = dir_clase+'/'+elemento\n",
    "        shutil.copy(elemento,dest_dir+\"/valid/\"+nombre_clase)\n",
    "        contador = contador+1\n",
    "\n",
    "    while len(lista) > 0:\n",
    "        elemento = random.choice(lista)\n",
    "        lista.remove(elemento)\n",
    "        elemento = dir_clase+'/'+elemento\n",
    "        shutil.copy(elemento,dest_dir+\"/train/\"+nombre_clase)\n",
    "        contador = contador+1\n",
    "\n",
    "def crearConjuntos( root_dir, dest_dir ):\n",
    "    if os.path.exists(dest_dir+\"/train\"):\n",
    "        shutil.rmtree(dest_dir+\"/train\")\n",
    "    if os.path.exists(dest_dir+\"/test\"):\n",
    "        shutil.rmtree(dest_dir+\"/test\")\n",
    "    if os.path.exists(dest_dir+\"/valid\"):\n",
    "        shutil.rmtree(dest_dir+\"/valid\")\n",
    "    os.mkdir(dest_dir+\"/train\")\n",
    "    os.mkdir(dest_dir+\"/test\")\n",
    "    os.mkdir(dest_dir+\"/valid\")\n",
    "    crearSubConjuntos( '01-Normal', root_dir+'/01-Normal', dest_dir )\n",
    "    crearSubConjuntos( '02-Tapered', root_dir+'/02-Tapered', dest_dir )\n",
    "    crearSubConjuntos( '03-Pyriform', root_dir+'/03-Pyriform', dest_dir )\n",
    "    crearSubConjuntos( '04-Small', root_dir+'/04-Small', dest_dir )\n",
    "    crearSubConjuntos( '05-Amorphous', root_dir+'/05-Amorphous', dest_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbe3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f2744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be3959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyImageFromList( root_dir, dest_dir, image_list ):\n",
    "        element = random.choice(image_list)\n",
    "        image_list.remove(element)\n",
    "        element = root_dir+'/'+class_name+'/'+element\n",
    "        shutil.copy(element,dest_dir+'/'+class_name)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a420e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kFold_classImages( class_name, root_dir, list_paths, valid_path):\n",
    "    images_in_folder = os.listdir(root_dir+'/'+class_name)\n",
    "    len_images = len(images_in_folder)\n",
    "    percentage_per_fold = (100/len(list_paths))/100\n",
    "\n",
    "    for i in range(len(list_paths)):\n",
    "        dest_dir = list_paths[i]\n",
    "        if (i == 0):\n",
    "            count = 0\n",
    "            while (len_images*percentage_per_fold)*0.2 > count:\n",
    "                element = random.choice(images_in_folder)\n",
    "                images_in_folder.remove(element)\n",
    "                element = root_dir+'/'+class_name+'/'+element\n",
    "                shutil.copy(element,valid_path+'/'+class_name)  \n",
    "                count = count+1 \n",
    "            count = 0\n",
    "            while (len_images*percentage_per_fold)*0.8 > count:\n",
    "                element = random.choice(images_in_folder)\n",
    "                images_in_folder.remove(element)\n",
    "                element = root_dir+'/'+class_name+'/'+element\n",
    "                shutil.copy(element,dest_dir+'/'+class_name)  \n",
    "                count = count+1\n",
    "                \n",
    "        elif ( i ==  len(list_paths)-1):\n",
    "            while len(images_in_folder) > 0:\n",
    "                element = random.choice(images_in_folder)\n",
    "                images_in_folder.remove(element)\n",
    "                element = root_dir+'/'+class_name+'/'+element\n",
    "                shutil.copy(element,dest_dir+'/'+class_name)                \n",
    "        else:\n",
    "            count = 0\n",
    "            while (len_images*percentage_per_fold) > count:\n",
    "                element = random.choice(images_in_folder)\n",
    "                images_in_folder.remove(element)\n",
    "                element = root_dir+'/'+class_name+'/'+element\n",
    "                shutil.copy(element,dest_dir+\"/\"+class_name)\n",
    "                count = count+1            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcb6eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14657/3550951569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrearDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/PA-expert-annotations.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/Partial-Agreement-Images/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/home/mcoronado/Escritorio/Codigo-Memoria/Data-set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14657/2646203433.py\u001b[0m in \u001b[0;36mcrearDataset\u001b[0;34m(path_expertAnotations, path_partialImages, dest_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrearDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_expertAnotations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_partialImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_expertAnotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/data/01-Normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/data/02-Tapered'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/data'"
     ]
    }
   ],
   "source": [
    "crearDataset(\"/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/PA-expert-annotations.txt\", '/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/Partial-Agreement-Images/',\"/home/mcoronado/Escritorio/Codigo-Memoria/Data-set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1652b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kFold_partitionImages( original_dir,dest_dir, k_folds ):\n",
    "    percentage_per_fold = int(100/k_folds)\n",
    "    if os.path.exists(dest_dir):\n",
    "        shutil.rmtree(dest_dir)   \n",
    "    os.mkdir(dest_dir)\n",
    "    \n",
    "    list_paths = []\n",
    "    for i in range(0,k_folds+1):\n",
    "        if (i == 0):\n",
    "            ifold_fileName = 'valid'\n",
    "        else:\n",
    "            ifold_fileName = 'fold_'+str(i)\n",
    "        ifold_path = dest_dir+ifold_fileName\n",
    "        if os.path.exists(ifold_path):\n",
    "            shutil.rmtree(ifold_path)\n",
    "        os.mkdir(ifold_path)\n",
    "        os.mkdir(ifold_path+'/01-Normal')\n",
    "        os.mkdir(ifold_path+'/02-Tapered')\n",
    "        os.mkdir(ifold_path+'/03-Pyriform')\n",
    "        os.mkdir(ifold_path+'/04-Small')\n",
    "        os.mkdir(ifold_path+'/05-Amorphous')\n",
    "        if( i!= 0):\n",
    "            list_paths.append(ifold_path)\n",
    "    valid_path = dest_dir+'valid'\n",
    "    generate_kFold_classImages( '01-Normal', original_dir, list_paths, valid_path)\n",
    "    generate_kFold_classImages( '02-Tapered', original_dir, list_paths, valid_path)\n",
    "    generate_kFold_classImages( '03-Pyriform', original_dir, list_paths, valid_path)\n",
    "    generate_kFold_classImages( '04-Small', original_dir, list_paths, valid_path)\n",
    "    generate_kFold_classImages( '05-Amorphous', original_dir, list_paths, valid_path)\n",
    "    return list_paths\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b6ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarImagenesAumentadas( image_dir ):\n",
    "    class_names = ['01-Normal', '02-Tapered', '03-Pyriform', '04-Small', '05-Amorphous']\n",
    "    for class_name in class_names:\n",
    "        if os.path.exists(image_dir+'/'+class_name+'/output'):\n",
    "            shutil.rmtree(image_dir+'/'+class_name+'/output')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9405ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_dataAugmentation( kfold_paths , n_images_target):\n",
    "    for i in range(len(kfold_paths)):\n",
    "        if (i == 0):\n",
    "            aumentarImagenesSCIAN( kfold_paths[i] ,int(n_images_target*0.80) )\n",
    "        else:\n",
    "            aumentarImagenesSCIAN( kfold_paths[i] ,n_images_target )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378b9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_dataAugmentation_delete( kfold_paths ):\n",
    "    for i in range(len(kfold_paths)):\n",
    "        eliminarImagenesAumentadas( kfold_paths[i] )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d2ed27b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def k_fold_moveTrainImages(n_kfold, kfold_paths, dest_dir):\n",
    "    # [nombreImagen, path_fold, original/aumentada]\n",
    "    all_images_objects = []\n",
    "    classes_names = ['01-Normal', '02-Tapered', '03-Pyriform', '04-Small', '05-Amorphous']\n",
    "    if os.path.exists(dest_dir+'/train'):\n",
    "        shutil.rmtree(dest_dir+'/train')   \n",
    "    os.mkdir(dest_dir+\"/train\")\n",
    "    for class_name in classes_names:\n",
    "        os.mkdir(dest_dir+\"/train/\"+class_name)\n",
    "        os.mkdir(dest_dir+\"/train/\"+class_name+'/output')\n",
    "    for i in range(0,len(kfold_paths)):\n",
    "        if (i != n_kfold-1):\n",
    "            path = kfold_paths[i]\n",
    "            for class_name in classes_names:\n",
    "                class_path = path+'/'+class_name\n",
    "                image_names= os.listdir(class_path)\n",
    "                for image in image_names:\n",
    "                    if image.endswith(\".tif\"):\n",
    "                        image_dir = class_path+'/'+image\n",
    "                        all_images_objects.append([image, class_path, 'original'])\n",
    "                        shutil.move( image_dir, dest_dir+'train/'+class_name)\n",
    "\n",
    "                augmentated_image_names= os.listdir(class_path+'/output')\n",
    "                for image in augmentated_image_names:\n",
    "                    if image.endswith(\".tif\"):\n",
    "                        image_dir = class_path+'/output/'+image\n",
    "                        all_images_objects.append([image, class_path+'/output', 'augmented'])\n",
    "                        shutil.move( image_dir, dest_dir+'train/'+class_name+'/output')\n",
    "    return all_images_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521449fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eea62b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kFold_validation( root_dir ):\n",
    "    root_dir = root_dir+'valid'\n",
    "    if os.path.exists(root_dir):\n",
    "        shutil.rmtree(root_dir)   \n",
    "    os.mkdir(root_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a6642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_folds = 5\n",
    "#list_kfold_paths = generate_kFold_partitionImages( original_dir='/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/data/', dest_dir='/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/', k_folds= k_folds)\n",
    "#k_fold_dataAugmentation(list_kfold_paths,1600)\n",
    "#k_fold_moveTrainImages(1,list_kfold_paths,'/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d4819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb005fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_kfold( n_fold , root_dir):\n",
    "    \n",
    "    return data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6335a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c74363c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contarArchivos(folder):\n",
    "    count = 0\n",
    "    for root_dir, cur_dir, files in os.walk(folder):\n",
    "        count += len(files)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa77a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_returnTrainImages( n_kfold, kfold_paths):\n",
    "    print('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "92710505",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_dataAugmentation_delete( list_kfold_paths ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0377c002",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3892630249.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_14657/3892630249.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def k_fold_returnTrainImages(n_kfold, kfold_paths, des_dir,all_dir_object):\u001b[0m\n\u001b[0m                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def k_fold_returnTrainImages(n_kfold, kfold_paths, des_dir,all_dir_object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf20c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d43e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c95d4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mdbloice/Augmentor/issues/125#issuecomment-410978015\n",
    "from Augmentor.Operations import Operation\n",
    "class TranslateImage(Operation):\n",
    "    # Here you can accept as many custom parameters as required:\n",
    "    def __init__(self, probability,max_left_translation,max_right_translation,max_down_translation,max_up_translation):\n",
    "        # Call the superclass's constructor (meaning you must\n",
    "        # supply a probability value):\n",
    "        Operation.__init__(self, probability)\n",
    "        # Set your custom operation's member variables here as required:\n",
    "        self.max_left_translation = -abs(max_left_translation)\n",
    "        self.max_right_translation = max_right_translation\n",
    "        self.max_down_translation = -abs(max_down_translation)\n",
    "        self.max_up_translation = max_up_translation\n",
    "\n",
    "    # Your class must implement the perform_operation method:\n",
    "    def perform_operation(self, images):\n",
    "        # Start of code to perform custom image operation.\n",
    "        def do(image):\n",
    "            random_left = random.randint(self.max_left_translation, 0)\n",
    "            random_right = random.randint(0, self.max_right_translation)\n",
    "            left_or_right = random.randint(0, 1)\n",
    "            translation_left_right = 0\n",
    "            if left_or_right == 0:\n",
    "                translation_left_right= random_left\n",
    "            elif left_or_right == 1:\n",
    "                translation_left_right = random_right\n",
    "            \n",
    "            random_down = random.randint(self.max_down_translation, 0)\n",
    "            random_up = random.randint(0, self.max_up_translation)\n",
    "            up_or_down = random.randint(0, 1)\n",
    "            translation_up_down = 0\n",
    "            if up_or_down == 0:\n",
    "                translation_up_down = random_up\n",
    "            elif up_or_down == 1:\n",
    "                translation_up_down = random_down\n",
    "            a = 1\n",
    "            b = 0\n",
    "            c = translation_left_right #left/right (i.e. 5/-5)\n",
    "            d = 0\n",
    "            e = 1\n",
    "            f = translation_up_down  #up/down (i.e. 5/-5)\n",
    "            #image = PIL.Image.fromarray(image)\n",
    "            image = image.transform(image.size, PIL.Image.AFFINE, (a, b, c, d, e, f))\n",
    "            return image\n",
    "        \n",
    "        augmented_images = []\n",
    "\n",
    "        for image in images:\n",
    "            augmented_images.append(do(image))\n",
    "\n",
    "        return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "641e11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "33506e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Diagnotics-10-00325\n",
    "def aumentarImagenesSCIAN(data_path, cantidad_imagenes):\n",
    "    #counts number of images in training data\n",
    "    cantidad_train_1= contarArchivos(data_path+'/01-Normal')\n",
    "    cantidad_train_2 = contarArchivos(data_path+'/02-Tapered')\n",
    "    cantidad_train_3 = contarArchivos(data_path+'/03-Pyriform')\n",
    "    cantidad_train_4 = contarArchivos(data_path+'/04-Small')\n",
    "    cantidad_train_5 = contarArchivos(data_path+'/05-Amorphous')\n",
    "\n",
    "    ## Se instancia un Augmentor\n",
    "    pipeline_normal = Augmentor.Pipeline(data_path+'/01-Normal')\n",
    "    pipeline_tapered = Augmentor.Pipeline(data_path+'/02-Tapered')\n",
    "    pipeline_pyriform = Augmentor.Pipeline(data_path+'/03-Pyriform')\n",
    "    pipeline_small = Augmentor.Pipeline(data_path+'/04-Small')\n",
    "    pipeline_morphous = Augmentor.Pipeline(data_path+'/05-Amorphous')\n",
    "\n",
    "    ## Rotation -25° a 25°\n",
    "    pipeline_normal.rotate_without_crop(probability=0.6, max_left_rotation=5, max_right_rotation=5)\n",
    "    pipeline_tapered.rotate_without_crop(probability=0.6, max_left_rotation=5, max_right_rotation=5)\n",
    "    pipeline_pyriform.rotate_without_crop(probability=0.6, max_left_rotation=5, max_right_rotation=5)\n",
    "    pipeline_small.rotate_without_crop(probability=0.6, max_left_rotation=5, max_right_rotation=5)\n",
    "    pipeline_morphous.rotate_without_crop(probability=0.6, max_left_rotation=5, max_right_rotation=5)\n",
    "\n",
    "    ## Vertical flip\n",
    "    pipeline_normal.flip_top_bottom(probability=0.6)\n",
    "    pipeline_tapered.flip_top_bottom(probability=0.6)\n",
    "    pipeline_pyriform.flip_top_bottom(probability=0.6)\n",
    "    pipeline_small.flip_top_bottom(probability=0.6)\n",
    "    pipeline_morphous.flip_top_bottom(probability=0.6)\n",
    "\n",
    "    ## Trasladation (max 6% de la imagen = 3 pixeles )\n",
    "    pipeline_normal.add_operation(TranslateImage(probability = 0.6, max_left_translation=3,max_right_translation=3,max_down_translation=3,max_up_translation=3))\n",
    "    pipeline_tapered.add_operation(TranslateImage(probability = 0.6, max_left_translation=3,max_right_translation=3,max_down_translation=3,max_up_translation=3))\n",
    "    pipeline_pyriform.add_operation(TranslateImage(probability = 0.6, max_left_translation=3,max_right_translation=3,max_down_translation=3,max_up_translation=3))\n",
    "    pipeline_small.add_operation(TranslateImage(probability = 0.6, max_left_translation=3,max_right_translation=3,max_down_translation=3,max_up_translation=3))\n",
    "    pipeline_morphous.add_operation(TranslateImage(probability = 0.6, max_left_translation=3,max_right_translation=3,max_down_translation=3,max_up_translation=3))\n",
    "\n",
    "    # Se restan para asimilar la distribucion original de las imagenes.\n",
    "    pipeline_normal.sample(cantidad_imagenes - cantidad_train_1)\n",
    "    pipeline_tapered.sample(cantidad_imagenes - cantidad_train_2)\n",
    "    pipeline_pyriform.sample(cantidad_imagenes - cantidad_train_3)\n",
    "    pipeline_small.sample(cantidad_imagenes - cantidad_train_4)\n",
    "    pipeline_morphous.sample(cantidad_imagenes - cantidad_train_5)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f69b717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
    "def crearDataGenerators(data_path):\n",
    "    \n",
    "    dataGen_train = ImageDataGenerator(rescale = 1./255,preprocessing_function= preprocess_input) \n",
    "    dataGen_valid = ImageDataGenerator(rescale = 1./255,preprocessing_function= preprocess_input)\n",
    "    dataGen_test = ImageDataGenerator(rescale = 1./255,preprocessing_function= preprocess_input)\n",
    "\n",
    "    #test different color maps -  class modes and cross validation types\n",
    "    train = dataGen_train.flow_from_directory(data_path+'/train',\n",
    "                                                     target_size = (35, 35),\n",
    "                                                     batch_size = 256,\n",
    "                                                     shuffle = True,\n",
    "                                                     class_mode=\"categorical\")\n",
    "\n",
    "    valid = dataGen_valid.flow_from_directory(data_path+'/valid',\n",
    "                                                target_size = (35, 35),\n",
    "                                                batch_size = 64,\n",
    "                                                shuffle = True,\n",
    "                                                class_mode=\"categorical\")\n",
    "\n",
    "    test = dataGen_test.flow_from_directory(data_path+'/test',\n",
    "                                                target_size = (35, 35),\n",
    "                                                batch_size = 1,\n",
    "                                                shuffle = True,\n",
    "                                                class_mode=\"categorical\")\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa49867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearCNN_simple():\n",
    "    #creating a model that will take inputs 32,32,1\n",
    "    cnn_model = Sequential()\n",
    "\n",
    "    #convolutional layer with 32 2x2 filters - output 14 x 14 active area\n",
    "    cnn_model.add(Conv2D(filters=35, kernel_size=(4,4), padding = 'same', activation='relu')) \n",
    "    cnn_model.add(BatchNormalization())\n",
    "\n",
    "    #2nd convolution with 64 filters  \n",
    "    cnn_model.add(Conv2D(filters=64, kernel_size=(2,2), padding = 'same', activation= 'relu'))\n",
    "    cnn_model.add(BatchNormalization())  \n",
    "\n",
    "    #MaxPooling - takes the max value of each 2x2 pool in the feature map\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "\n",
    "    #the result of kthe CNN is then flattened and placed into the \n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(576, activation='relu'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "\n",
    "    #widen layer\n",
    "    cnn_model.add(Dense(1024, activation='relu'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    #shrink layer\n",
    "    cnn_model.add(Dense(256, activation='relu'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    cnn_model.add(Dense(5))\n",
    "    cnn_model.add(BatchNormalization())            \n",
    "    cnn_model.add(Activation('softmax'))\n",
    "\n",
    "    cnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5575a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarModelo(modelo, epochs, train_data, valid_data, callbacks):\n",
    "    history = modelo.fit(train_data,\n",
    "            epochs=epochs, \n",
    "            validation_data=valid_data,\n",
    "            verbose = 1, \n",
    "            callbacks = callbacks) \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e9df5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/callbacks/\n",
    "# Se utilizo como referencia el trabajo de Ricardo Santos.\n",
    "def crearCallBacks(checkpoint_path):\n",
    "\n",
    "    #https://keras.io/api/callbacks/model_checkpoint/\n",
    "    model_checkPoint = ModelCheckpoint(filepath=checkpoint_path, verbose = 1, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "    #https://keras.io/api/callbacks/early_stopping/\n",
    "    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, restore_best_weights = True)\n",
    "\n",
    "    #https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0, verbose = 1)\n",
    "\n",
    "    cb = TimingCallback()    \n",
    "    return [model_checkPoint, cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fc47f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimirMetricas(y_train, pred_train , y_val, pred_val):\n",
    "    print( \" Conjunto train \"+\"\\n\")\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train)+\"\\n\")\n",
    "    print( \" Conjunto valid \"+\"\\n\")\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "539761fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluarModelo( modelo, test):\n",
    "    test_loss, test_acc = modelo.evaluate(test)\n",
    "    print('Test loss:', test_loss)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    #print(\"\\nTime:\",sum(modelo.callbacks.cb.logs)/60,\"min\")    \n",
    "    \n",
    "    prediction = modelo.predict( test )\n",
    "    clase_predecida = np.argmax(prediction,axis=1)\n",
    "    clase_verdadera = test.classes\n",
    "    class_labels = list(test.class_indices.keys())   \n",
    "    \n",
    "    print(confusion_matrix(clase_verdadera, clase_predecida))\n",
    "    print(classification_report(clase_verdadera, clase_predecida, target_names=class_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c5cb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancearValid( original_dir, obj_class_name):\n",
    "    classes_names = ['01-Normal', '02-Tapered', '03-Pyriform', '04-Small', '05-Amorphous']\n",
    "    valid_dir = original_dir+'/valid'\n",
    "    train_dir = original_dir+'/train'\n",
    "    \n",
    "    count_obj_class = contarArchivos(valid_dir+obj_class_name)\n",
    "    \n",
    "    for class_name in classes_names:\n",
    "        images_names = os.listdir(valid_dir+'/'+class_name)\n",
    "        while len(images_names) > count_obj_class:\n",
    "            element = random.choice(images_names)\n",
    "            images_names.remove(element)\n",
    "            element_dir=valid_dir+'/'+class_name+'/'+element\n",
    "            shutil.move(element_dir, train_dir+'/'+class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d2791d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32000 images belonging to 5 classes.\n",
      "Found 75 images belonging to 5 classes.\n",
      "Found 229 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#crearDataset(\"/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/PA-expert-annotations.txt\", '/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/Partial-Agreement-Images/',\"/home/mcoronado/Escritorio/Codigo-Memoria/Data-set\")\n",
    "#crearConjuntos('/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/data','/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/final_data')\n",
    "#aumentarImagenesSCIAN('/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/final_data/train', 6400)\n",
    "#balancearValid('/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/final_data','/04-Small')\n",
    "train,valid,test = crearDataGenerators('/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/final_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c9816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f2b1c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def generateVGG16(input_shape, n_classes, fine_tune=0):\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=input_shape)\n",
    "    if( fine_tune > 0):\n",
    "        for layer in base_model.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False    \n",
    "    top_model = base_model.output\n",
    "    top_model = Flatten(name='flatten')(top_model)\n",
    "    top_model = Dense(128, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.05)(top_model)\n",
    "    \n",
    "    top_model = Dense(64, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    \n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    \n",
    "    final_model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0005,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.0055)\n",
    "    \n",
    "    final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return final_model\n",
    "    #flatten_layer = layers.Flatten()\n",
    "    #dense_layer_1 = layers.Dense(1024, activation='relu')\n",
    "    #dense_layer_2 = layers.Dense(512, activation='relu')\n",
    "    #prediction_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "    #final_mode = models.Sequential([\n",
    "    #    base_model,\n",
    "    #    flatten_layer,\n",
    "    #    dense_layer_1,\n",
    "    #    dense_layer_2,\n",
    "    #    prediction_layer\n",
    "    #])\n",
    "    #final_mode.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    #              loss='categorical_crossentropy',\n",
    "    #              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d8cf83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a40bdbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = generateVGG16(Input(shape=(35, 35, 3)), 5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30f3152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 35, 35, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 35, 35, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 35, 35, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 17, 17, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,788,933\n",
      "Trainable params: 74,245\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9f683b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7862\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52000, saving model to /home/mcoronado/Escritorio/Models_VGG16_V6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 98s 786ms/step - loss: 0.5675 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.7909\n",
      "Epoch 2: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5631 - accuracy: 0.7909 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7881\n",
      "Epoch 3: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5659 - accuracy: 0.7881 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7867\n",
      "Epoch 4: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5665 - accuracy: 0.7867 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.7858\n",
      "Epoch 5: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5661 - accuracy: 0.7858 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7854\n",
      "Epoch 6: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5675 - accuracy: 0.7854 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.7862\n",
      "Epoch 7: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5689 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5696 - accuracy: 0.7850\n",
      "Epoch 8: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5696 - accuracy: 0.7850 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.7890\n",
      "Epoch 9: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5617 - accuracy: 0.7890 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7893\n",
      "Epoch 10: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5669 - accuracy: 0.7893 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.7877\n",
      "Epoch 11: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5684 - accuracy: 0.7877 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7883\n",
      "Epoch 12: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5657 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7886\n",
      "Epoch 13: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5637 - accuracy: 0.7886 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7883\n",
      "Epoch 14: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5667 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.7873\n",
      "Epoch 15: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5681 - accuracy: 0.7873 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7871\n",
      "Epoch 16: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5660 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.7859\n",
      "Epoch 17: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 571ms/step - loss: 0.5674 - accuracy: 0.7859 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7872\n",
      "Epoch 18: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5675 - accuracy: 0.7872 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7888\n",
      "Epoch 19: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5637 - accuracy: 0.7888 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.7875\n",
      "Epoch 20: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5644 - accuracy: 0.7875 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.7887\n",
      "Epoch 21: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5648 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.7849\n",
      "Epoch 22: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5648 - accuracy: 0.7849 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7883\n",
      "Epoch 23: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5662 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7889\n",
      "Epoch 24: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5680 - accuracy: 0.7889 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.7880\n",
      "Epoch 25: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5661 - accuracy: 0.7880 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7885\n",
      "Epoch 26: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 0.5657 - accuracy: 0.7885 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7861\n",
      "Epoch 27: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5658 - accuracy: 0.7861 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.7883\n",
      "Epoch 28: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5647 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7889\n",
      "Epoch 29: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5668 - accuracy: 0.7889 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.7882\n",
      "Epoch 30: val_accuracy did not improve from 0.52000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5688 - accuracy: 0.7882 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.7874\n",
      "Epoch 31: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5681 - accuracy: 0.7874 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7901\n",
      "Epoch 32: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5653 - accuracy: 0.7901 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7892\n",
      "Epoch 33: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5653 - accuracy: 0.7892 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7879\n",
      "Epoch 34: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5656 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7900\n",
      "Epoch 35: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5649 - accuracy: 0.7900 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7884\n",
      "Epoch 36: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5669 - accuracy: 0.7884 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7874\n",
      "Epoch 37: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 70s 563ms/step - loss: 0.5662 - accuracy: 0.7874 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7884\n",
      "Epoch 38: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5659 - accuracy: 0.7884 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7873\n",
      "Epoch 39: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5655 - accuracy: 0.7873 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7868\n",
      "Epoch 40: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5665 - accuracy: 0.7868 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7858\n",
      "Epoch 41: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5665 - accuracy: 0.7858 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.7870\n",
      "Epoch 42: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5686 - accuracy: 0.7870 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7877\n",
      "Epoch 43: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5657 - accuracy: 0.7877 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7872\n",
      "Epoch 44: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5675 - accuracy: 0.7872 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7883\n",
      "Epoch 45: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 0.5677 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7863\n",
      "Epoch 46: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5687 - accuracy: 0.7863 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7880\n",
      "Epoch 47: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5641 - accuracy: 0.7880 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7873\n",
      "Epoch 48: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5662 - accuracy: 0.7873 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7885\n",
      "Epoch 49: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5660 - accuracy: 0.7885 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7881\n",
      "Epoch 50: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5671 - accuracy: 0.7881 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7877\n",
      "Epoch 51: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 0.5680 - accuracy: 0.7877 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7879\n",
      "Epoch 52: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 569ms/step - loss: 0.5649 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7873\n",
      "Epoch 53: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5672 - accuracy: 0.7873 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7868\n",
      "Epoch 54: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5673 - accuracy: 0.7868 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.7876\n",
      "Epoch 55: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5674 - accuracy: 0.7876 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7851\n",
      "Epoch 56: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5680 - accuracy: 0.7851 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7851\n",
      "Epoch 57: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5665 - accuracy: 0.7851 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7860\n",
      "Epoch 58: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 0.5667 - accuracy: 0.7860 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7885\n",
      "Epoch 59: val_accuracy did not improve from 0.52000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5655 - accuracy: 0.7885 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.7887\n",
      "Epoch 60: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5648 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7858\n",
      "Epoch 61: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5677 - accuracy: 0.7858 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.7864\n",
      "Epoch 62: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5684 - accuracy: 0.7864 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7890\n",
      "Epoch 63: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5641 - accuracy: 0.7890 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7889\n",
      "Epoch 64: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5676 - accuracy: 0.7889 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.7897\n",
      "Epoch 65: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5626 - accuracy: 0.7897 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7893\n",
      "Epoch 66: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5687 - accuracy: 0.7893 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7880\n",
      "Epoch 67: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 0.5662 - accuracy: 0.7880 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.7843\n",
      "Epoch 68: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5694 - accuracy: 0.7843 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7889\n",
      "Epoch 69: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5656 - accuracy: 0.7889 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.7899\n",
      "Epoch 70: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5645 - accuracy: 0.7899 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.7862\n",
      "Epoch 71: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5688 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.7847\n",
      "Epoch 72: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5685 - accuracy: 0.7847 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7892\n",
      "Epoch 73: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5666 - accuracy: 0.7892 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7884\n",
      "Epoch 74: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5675 - accuracy: 0.7884 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.7886\n",
      "Epoch 75: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5650 - accuracy: 0.7886 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7883\n",
      "Epoch 76: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5670 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7855\n",
      "Epoch 77: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 569ms/step - loss: 0.5679 - accuracy: 0.7855 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7892\n",
      "Epoch 78: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5652 - accuracy: 0.7892 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7871\n",
      "Epoch 79: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5682 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7893\n",
      "Epoch 80: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5675 - accuracy: 0.7893 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.7904\n",
      "Epoch 81: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5634 - accuracy: 0.7904 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7862\n",
      "Epoch 82: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5659 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.7869\n",
      "Epoch 83: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5639 - accuracy: 0.7869 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.7866\n",
      "Epoch 84: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5648 - accuracy: 0.7866 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7878\n",
      "Epoch 85: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5683 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7871\n",
      "Epoch 86: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5653 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7877\n",
      "Epoch 87: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5655 - accuracy: 0.7877 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7868\n",
      "Epoch 88: val_accuracy did not improve from 0.52000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5672 - accuracy: 0.7868 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7862\n",
      "Epoch 89: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5671 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.7856\n",
      "Epoch 90: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5688 - accuracy: 0.7856 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7869\n",
      "Epoch 91: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5668 - accuracy: 0.7869 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7878\n",
      "Epoch 92: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5679 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.7874\n",
      "Epoch 93: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5694 - accuracy: 0.7874 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.7886\n",
      "Epoch 94: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5650 - accuracy: 0.7886 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7878\n",
      "Epoch 95: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5660 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7878\n",
      "Epoch 96: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5682 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7873\n",
      "Epoch 97: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5659 - accuracy: 0.7873 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7868\n",
      "Epoch 98: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5675 - accuracy: 0.7868 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.7912\n",
      "Epoch 99: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5664 - accuracy: 0.7912 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7871\n",
      "Epoch 100: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5682 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7867\n",
      "Epoch 101: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5683 - accuracy: 0.7867 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7866\n",
      "Epoch 102: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 72s 573ms/step - loss: 0.5673 - accuracy: 0.7866 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7848\n",
      "Epoch 103: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5680 - accuracy: 0.7848 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7888\n",
      "Epoch 104: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5666 - accuracy: 0.7888 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.7895\n",
      "Epoch 105: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5650 - accuracy: 0.7895 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.7873\n",
      "Epoch 106: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5645 - accuracy: 0.7873 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.7850\n",
      "Epoch 107: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5692 - accuracy: 0.7850 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7871\n",
      "Epoch 108: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5677 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7864\n",
      "Epoch 109: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5657 - accuracy: 0.7864 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.7868\n",
      "Epoch 110: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5663 - accuracy: 0.7868 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7881\n",
      "Epoch 111: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5675 - accuracy: 0.7881 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.7888\n",
      "Epoch 112: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5634 - accuracy: 0.7888 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7879\n",
      "Epoch 113: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5653 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7886\n",
      "Epoch 114: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5658 - accuracy: 0.7886 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.7877\n",
      "Epoch 115: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5688 - accuracy: 0.7877 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.7869\n",
      "Epoch 116: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5664 - accuracy: 0.7869 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 0s - loss: 0.5696 - accuracy: 0.7878\n",
      "Epoch 117: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5696 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.7881\n",
      "Epoch 118: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 0.5647 - accuracy: 0.7881 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.7903\n",
      "Epoch 119: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5639 - accuracy: 0.7903 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.7883\n",
      "Epoch 120: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5686 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.7862\n",
      "Epoch 121: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5700 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.7864\n",
      "Epoch 122: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5678 - accuracy: 0.7864 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7866\n",
      "Epoch 123: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5669 - accuracy: 0.7866 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7881\n",
      "Epoch 124: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5667 - accuracy: 0.7881 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.7883\n",
      "Epoch 125: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5678 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7883\n",
      "Epoch 126: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5652 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7883\n",
      "Epoch 127: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5677 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7887\n",
      "Epoch 128: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 569ms/step - loss: 0.5668 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.7897\n",
      "Epoch 129: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5638 - accuracy: 0.7897 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7865\n",
      "Epoch 130: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5665 - accuracy: 0.7865 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7887\n",
      "Epoch 131: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5672 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7879\n",
      "Epoch 132: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5652 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7882\n",
      "Epoch 133: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5668 - accuracy: 0.7882 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7891\n",
      "Epoch 134: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5658 - accuracy: 0.7891 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7876\n",
      "Epoch 135: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5676 - accuracy: 0.7876 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.7887\n",
      "Epoch 136: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5664 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5651 - accuracy: 0.7893\n",
      "Epoch 137: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5651 - accuracy: 0.7893 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7886\n",
      "Epoch 138: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5673 - accuracy: 0.7886 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7882\n",
      "Epoch 139: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5680 - accuracy: 0.7882 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.7891\n",
      "Epoch 140: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5640 - accuracy: 0.7891 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.7869\n",
      "Epoch 141: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5664 - accuracy: 0.7869 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7863\n",
      "Epoch 142: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5670 - accuracy: 0.7863 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7888\n",
      "Epoch 143: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5652 - accuracy: 0.7888 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7887\n",
      "Epoch 144: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5660 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.7867\n",
      "Epoch 145: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5681 - accuracy: 0.7867 - val_loss: 1.4394 - val_accuracy: 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7878\n",
      "Epoch 146: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5662 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7884\n",
      "Epoch 147: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5657 - accuracy: 0.7884 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7891\n",
      "Epoch 148: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5657 - accuracy: 0.7891 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7868\n",
      "Epoch 149: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5649 - accuracy: 0.7868 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7882\n",
      "Epoch 150: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5670 - accuracy: 0.7882 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7877\n",
      "Epoch 151: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5653 - accuracy: 0.7877 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7867\n",
      "Epoch 152: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5669 - accuracy: 0.7867 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7878\n",
      "Epoch 153: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 72s 571ms/step - loss: 0.5671 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7872\n",
      "Epoch 154: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5676 - accuracy: 0.7872 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7871\n",
      "Epoch 155: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5667 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.7898\n",
      "Epoch 156: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5635 - accuracy: 0.7898 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.7875\n",
      "Epoch 157: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5648 - accuracy: 0.7875 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.7858\n",
      "Epoch 158: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5674 - accuracy: 0.7858 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7883\n",
      "Epoch 159: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5673 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7862\n",
      "Epoch 160: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5666 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.7883\n",
      "Epoch 161: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5647 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7881\n",
      "Epoch 162: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5666 - accuracy: 0.7881 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.7874\n",
      "Epoch 163: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5691 - accuracy: 0.7874 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.7891\n",
      "Epoch 164: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5636 - accuracy: 0.7891 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.7862\n",
      "Epoch 165: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5678 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7878\n",
      "Epoch 166: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5656 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7879\n",
      "Epoch 167: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5658 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7854\n",
      "Epoch 168: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5662 - accuracy: 0.7854 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7882\n",
      "Epoch 169: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 0.5667 - accuracy: 0.7882 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7861\n",
      "Epoch 170: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 0.5657 - accuracy: 0.7861 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7887\n",
      "Epoch 171: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5675 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7888\n",
      "Epoch 172: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5668 - accuracy: 0.7888 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7858\n",
      "Epoch 173: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5662 - accuracy: 0.7858 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.7871\n",
      "Epoch 174: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5648 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7866\n",
      "Epoch 175: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5666 - accuracy: 0.7866 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.7895\n",
      "Epoch 176: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5633 - accuracy: 0.7895 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7874\n",
      "Epoch 177: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5682 - accuracy: 0.7874 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7845\n",
      "Epoch 178: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5683 - accuracy: 0.7845 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7862\n",
      "Epoch 179: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 0.5687 - accuracy: 0.7862 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7892\n",
      "Epoch 180: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5649 - accuracy: 0.7892 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7871\n",
      "Epoch 181: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 0.5668 - accuracy: 0.7871 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.7878\n",
      "Epoch 182: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5661 - accuracy: 0.7878 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7866\n",
      "Epoch 183: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5673 - accuracy: 0.7866 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5642 - accuracy: 0.7879\n",
      "Epoch 184: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5642 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7890\n",
      "Epoch 185: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5655 - accuracy: 0.7890 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.7879\n",
      "Epoch 186: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5678 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.7893\n",
      "Epoch 187: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5645 - accuracy: 0.7893 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7874\n",
      "Epoch 188: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5680 - accuracy: 0.7874 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7882\n",
      "Epoch 189: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 0.5665 - accuracy: 0.7882 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.7867\n",
      "Epoch 190: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5702 - accuracy: 0.7867 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.7875\n",
      "Epoch 191: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.5689 - accuracy: 0.7875 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7879\n",
      "Epoch 192: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5653 - accuracy: 0.7879 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7885\n",
      "Epoch 193: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5667 - accuracy: 0.7885 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.7866\n",
      "Epoch 194: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5666 - accuracy: 0.7866 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7887\n",
      "Epoch 195: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5652 - accuracy: 0.7887 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.7872\n",
      "Epoch 196: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5659 - accuracy: 0.7872 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7883\n",
      "Epoch 197: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.5656 - accuracy: 0.7883 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7874\n",
      "Epoch 198: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5656 - accuracy: 0.7874 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.7885\n",
      "Epoch 199: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5638 - accuracy: 0.7885 - val_loss: 1.4394 - val_accuracy: 0.5200\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7891\n",
      "Epoch 200: val_accuracy did not improve from 0.52000\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 0.5669 - accuracy: 0.7891 - val_loss: 1.4394 - val_accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "callbacks = crearCallBacks('/home/mcoronado/Escritorio/Models_VGG16_V6')\n",
    "model_history11 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1196e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 2s 9ms/step - loss: 1.1566 - accuracy: 0.5022\n",
      "Test loss: 1.1566131114959717\n",
      "Test accuracy: 0.5021833777427673\n",
      "229/229 [==============================] - 2s 8ms/step\n",
      "[[ 1  4  5  0 10]\n",
      " [ 7 10  2  5 22]\n",
      " [ 4  4  1  2  5]\n",
      " [ 2  6  2  0  5]\n",
      " [16 37 15 11 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.03      0.05      0.04        20\n",
      "  02-Tapered       0.16      0.22      0.19        46\n",
      " 03-Pyriform       0.04      0.06      0.05        16\n",
      "    04-Small       0.00      0.00      0.00        15\n",
      "05-Amorphous       0.56      0.40      0.47       132\n",
      "\n",
      "    accuracy                           0.28       229\n",
      "   macro avg       0.16      0.15      0.15       229\n",
      "weighted avg       0.36      0.28      0.31       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7b86f5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.5533 - accuracy: 0.3062\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41333, saving model to /home/mcoronado/Escritorio/Models_VGG16_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 114s 4s/step - loss: 1.5533 - accuracy: 0.3062 - val_loss: 1.3993 - val_accuracy: 0.4133\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.3708 - accuracy: 0.4281\n",
      "Epoch 2: val_accuracy improved from 0.41333 to 0.50667, saving model to /home/mcoronado/Escritorio/Models_VGG16_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 74s 2s/step - loss: 1.3708 - accuracy: 0.4281 - val_loss: 1.2150 - val_accuracy: 0.5067\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.2483 - accuracy: 0.4802\n",
      "Epoch 3: val_accuracy improved from 0.50667 to 0.53333, saving model to /home/mcoronado/Escritorio/Models_VGG16_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 74s 2s/step - loss: 1.2483 - accuracy: 0.4802 - val_loss: 1.1346 - val_accuracy: 0.5333\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.1711 - accuracy: 0.5210\n",
      "Epoch 4: val_accuracy did not improve from 0.53333\n",
      "32/32 [==============================] - 71s 2s/step - loss: 1.1711 - accuracy: 0.5210 - val_loss: 1.1033 - val_accuracy: 0.5333\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.1107 - accuracy: 0.5549\n",
      "Epoch 5: val_accuracy did not improve from 0.53333\n",
      "32/32 [==============================] - 72s 2s/step - loss: 1.1107 - accuracy: 0.5549 - val_loss: 1.0773 - val_accuracy: 0.5333\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.0684 - accuracy: 0.5675\n",
      "Epoch 6: val_accuracy improved from 0.53333 to 0.54667, saving model to /home/mcoronado/Escritorio/Models_VGG16_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 73s 2s/step - loss: 1.0684 - accuracy: 0.5675 - val_loss: 1.0753 - val_accuracy: 0.5467\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.0337 - accuracy: 0.5864\n",
      "Epoch 7: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 1.0337 - accuracy: 0.5864 - val_loss: 1.0619 - val_accuracy: 0.5067\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.6048\n",
      "Epoch 8: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.9992 - accuracy: 0.6048 - val_loss: 1.0824 - val_accuracy: 0.4933\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.9722 - accuracy: 0.6203\n",
      "Epoch 9: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.9722 - accuracy: 0.6203 - val_loss: 1.0399 - val_accuracy: 0.4933\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.9426 - accuracy: 0.6307\n",
      "Epoch 10: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.9426 - accuracy: 0.6307 - val_loss: 1.0444 - val_accuracy: 0.4800\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.9155 - accuracy: 0.6432\n",
      "Epoch 11: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.9155 - accuracy: 0.6432 - val_loss: 1.0672 - val_accuracy: 0.4933\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8940 - accuracy: 0.6512\n",
      "Epoch 12: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8940 - accuracy: 0.6512 - val_loss: 1.0595 - val_accuracy: 0.4667\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8735 - accuracy: 0.6627\n",
      "Epoch 13: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8735 - accuracy: 0.6627 - val_loss: 1.0667 - val_accuracy: 0.4800\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.6676\n",
      "Epoch 14: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8564 - accuracy: 0.6676 - val_loss: 1.0631 - val_accuracy: 0.5067\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8401 - accuracy: 0.6727\n",
      "Epoch 15: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8401 - accuracy: 0.6727 - val_loss: 1.0902 - val_accuracy: 0.4800\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8209 - accuracy: 0.6830\n",
      "Epoch 16: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.8209 - accuracy: 0.6830 - val_loss: 1.1149 - val_accuracy: 0.4933\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8057 - accuracy: 0.6906\n",
      "Epoch 17: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.8057 - accuracy: 0.6906 - val_loss: 1.0919 - val_accuracy: 0.5067\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7885 - accuracy: 0.6968\n",
      "Epoch 18: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.7885 - accuracy: 0.6968 - val_loss: 1.0968 - val_accuracy: 0.4667\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.7018\n",
      "Epoch 19: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.7752 - accuracy: 0.7018 - val_loss: 1.0812 - val_accuracy: 0.4800\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7073\n",
      "Epoch 20: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.7646 - accuracy: 0.7073 - val_loss: 1.0915 - val_accuracy: 0.4933\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7495 - accuracy: 0.7143\n",
      "Epoch 21: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.7495 - accuracy: 0.7143 - val_loss: 1.1294 - val_accuracy: 0.4933\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7359 - accuracy: 0.7193\n",
      "Epoch 22: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.7359 - accuracy: 0.7193 - val_loss: 1.1291 - val_accuracy: 0.5067\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7257 - accuracy: 0.7234\n",
      "Epoch 23: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.7257 - accuracy: 0.7234 - val_loss: 1.1647 - val_accuracy: 0.5067\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.7256\n",
      "Epoch 24: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.7175 - accuracy: 0.7256 - val_loss: 1.1469 - val_accuracy: 0.5200\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.7351\n",
      "Epoch 25: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.7031 - accuracy: 0.7351 - val_loss: 1.1670 - val_accuracy: 0.5200\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.7359\n",
      "Epoch 26: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6942 - accuracy: 0.7359 - val_loss: 1.1640 - val_accuracy: 0.5067\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.7399\n",
      "Epoch 27: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6826 - accuracy: 0.7399 - val_loss: 1.1823 - val_accuracy: 0.5067\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.7458\n",
      "Epoch 28: val_accuracy did not improve from 0.54667\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.6781 - accuracy: 0.7458 - val_loss: 1.2305 - val_accuracy: 0.5067\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.7500\n",
      "Epoch 29: val_accuracy did not improve from 0.54667\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6674 - accuracy: 0.7500 - val_loss: 1.2108 - val_accuracy: 0.5333\n",
      "Epoch 29: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = crearCallBacks('/home/mcoronado/Escritorio/Models_VGG16_V2')\n",
    "model_history11 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "47fc879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 3s 9ms/step - loss: 1.1539 - accuracy: 0.5153\n",
      "Test loss: 1.1538959741592407\n",
      "Test accuracy: 0.5152838230133057\n",
      "229/229 [==============================] - 3s 9ms/step\n",
      "[[ 1  2  4  1 12]\n",
      " [ 4  5 10  2 25]\n",
      " [ 5  2  3  1  5]\n",
      " [ 2  1  3  4  5]\n",
      " [13 14 28 12 65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.04      0.05      0.04        20\n",
      "  02-Tapered       0.21      0.11      0.14        46\n",
      " 03-Pyriform       0.06      0.19      0.09        16\n",
      "    04-Small       0.20      0.27      0.23        15\n",
      "05-Amorphous       0.58      0.49      0.53       132\n",
      "\n",
      "    accuracy                           0.34       229\n",
      "   macro avg       0.22      0.22      0.21       229\n",
      "weighted avg       0.40      0.34      0.36       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96ba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c148d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.7271\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52000, saving model to /home/mcoronado/Escritorio/Models_VGG16_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 10s 191ms/step - loss: 0.7055 - accuracy: 0.7271 - val_loss: 1.1023 - val_accuracy: 0.5200 - lr: 5.0000e-04\n",
      "Epoch 2/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.7017 - accuracy: 0.7268\n",
      "Epoch 2: val_accuracy improved from 0.52000 to 0.53333, saving model to /home/mcoronado/Escritorio/Models_VGG16_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 10s 199ms/step - loss: 0.7017 - accuracy: 0.7268 - val_loss: 1.1120 - val_accuracy: 0.5333 - lr: 5.0000e-04\n",
      "Epoch 3/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.7299\n",
      "Epoch 3: val_accuracy did not improve from 0.53333\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.6902 - accuracy: 0.7299 - val_loss: 1.1335 - val_accuracy: 0.4667 - lr: 5.0000e-04\n",
      "Epoch 4/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.7369\n",
      "Epoch 4: val_accuracy did not improve from 0.53333\n",
      "52/52 [==============================] - 8s 154ms/step - loss: 0.6869 - accuracy: 0.7369 - val_loss: 1.0702 - val_accuracy: 0.4800 - lr: 5.0000e-04\n",
      "Epoch 5/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.7473\n",
      "Epoch 5: val_accuracy did not improve from 0.53333\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.6624 - accuracy: 0.7473 - val_loss: 1.2884 - val_accuracy: 0.5067 - lr: 5.0000e-04\n",
      "Epoch 6/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.7341\n",
      "Epoch 6: val_accuracy improved from 0.53333 to 0.56000, saving model to /home/mcoronado/Escritorio/Models_VGG16_V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 10s 192ms/step - loss: 0.6688 - accuracy: 0.7341 - val_loss: 1.2039 - val_accuracy: 0.5600 - lr: 5.0000e-04\n",
      "Epoch 7/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.7518\n",
      "Epoch 7: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 152ms/step - loss: 0.6491 - accuracy: 0.7518 - val_loss: 1.1678 - val_accuracy: 0.5467 - lr: 5.0000e-04\n",
      "Epoch 8/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7518\n",
      "Epoch 8: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 156ms/step - loss: 0.6419 - accuracy: 0.7518 - val_loss: 1.2447 - val_accuracy: 0.5333 - lr: 5.0000e-04\n",
      "Epoch 9/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.7689\n",
      "Epoch 9: val_accuracy did not improve from 0.56000\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.6207 - accuracy: 0.7689 - val_loss: 1.2412 - val_accuracy: 0.5200 - lr: 5.0000e-04\n",
      "Epoch 10/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.7595\n",
      "Epoch 10: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 150ms/step - loss: 0.6183 - accuracy: 0.7595 - val_loss: 1.2961 - val_accuracy: 0.5333 - lr: 2.5000e-04\n",
      "Epoch 11/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.7659\n",
      "Epoch 11: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 150ms/step - loss: 0.6096 - accuracy: 0.7659 - val_loss: 1.2660 - val_accuracy: 0.5333 - lr: 2.5000e-04\n",
      "Epoch 12/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7777\n",
      "Epoch 12: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 156ms/step - loss: 0.5990 - accuracy: 0.7777 - val_loss: 1.2152 - val_accuracy: 0.5467 - lr: 2.5000e-04\n",
      "Epoch 13/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.7741\n",
      "Epoch 13: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 160ms/step - loss: 0.5935 - accuracy: 0.7741 - val_loss: 1.2072 - val_accuracy: 0.5200 - lr: 2.5000e-04\n",
      "Epoch 14/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7735\n",
      "Epoch 14: val_accuracy did not improve from 0.56000\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "52/52 [==============================] - 8s 161ms/step - loss: 0.5875 - accuracy: 0.7735 - val_loss: 1.2263 - val_accuracy: 0.5467 - lr: 2.5000e-04\n",
      "Epoch 15/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7835\n",
      "Epoch 15: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 154ms/step - loss: 0.5847 - accuracy: 0.7835 - val_loss: 1.2624 - val_accuracy: 0.5600 - lr: 1.2500e-04\n",
      "Epoch 16/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.7817\n",
      "Epoch 16: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.5783 - accuracy: 0.7817 - val_loss: 1.2701 - val_accuracy: 0.5200 - lr: 1.2500e-04\n",
      "Epoch 17/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.7854\n",
      "Epoch 17: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 150ms/step - loss: 0.5766 - accuracy: 0.7854 - val_loss: 1.3306 - val_accuracy: 0.5200 - lr: 1.2500e-04\n",
      "Epoch 18/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.7829\n",
      "Epoch 18: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 152ms/step - loss: 0.5640 - accuracy: 0.7829 - val_loss: 1.2451 - val_accuracy: 0.5467 - lr: 1.2500e-04\n",
      "Epoch 19/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.7851\n",
      "Epoch 19: val_accuracy did not improve from 0.56000\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "52/52 [==============================] - 8s 150ms/step - loss: 0.5606 - accuracy: 0.7851 - val_loss: 1.3065 - val_accuracy: 0.5333 - lr: 1.2500e-04\n",
      "Epoch 20/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7863\n",
      "Epoch 20: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.5641 - accuracy: 0.7863 - val_loss: 1.2416 - val_accuracy: 0.5200 - lr: 6.2500e-05\n",
      "Epoch 21/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.7921\n",
      "Epoch 21: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 152ms/step - loss: 0.5583 - accuracy: 0.7921 - val_loss: 1.2736 - val_accuracy: 0.5333 - lr: 6.2500e-05\n",
      "Epoch 22/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.8006\n",
      "Epoch 22: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.5493 - accuracy: 0.8006 - val_loss: 1.2996 - val_accuracy: 0.5200 - lr: 6.2500e-05\n",
      "Epoch 23/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7939\n",
      "Epoch 23: val_accuracy did not improve from 0.56000\n",
      "52/52 [==============================] - 8s 152ms/step - loss: 0.5531 - accuracy: 0.7939 - val_loss: 1.2805 - val_accuracy: 0.5200 - lr: 6.2500e-05\n",
      "Epoch 24/200\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.7939\n",
      "Epoch 24: val_accuracy did not improve from 0.56000\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.5487 - accuracy: 0.7939 - val_loss: 1.2342 - val_accuracy: 0.5333 - lr: 6.2500e-05\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = crearCallBacks('/home/mcoronado/Escritorio/Models_VGG16_V2')\n",
    "model_history11 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f489c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x7f79c837eed0>\n"
     ]
    }
   ],
   "source": [
    "print(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8479db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 2s 9ms/step - loss: 1.1299 - accuracy: 0.5371\n",
      "Test loss: 1.1298741102218628\n",
      "Test accuracy: 0.5371178984642029\n",
      "229/229 [==============================] - 2s 9ms/step\n",
      "[[ 4  5  2  2  7]\n",
      " [ 4 12  4  2 24]\n",
      " [ 4  0  4  1  7]\n",
      " [ 3  4  2  0  6]\n",
      " [26 18 19  9 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.10      0.20      0.13        20\n",
      "  02-Tapered       0.31      0.26      0.28        46\n",
      " 03-Pyriform       0.13      0.25      0.17        16\n",
      "    04-Small       0.00      0.00      0.00        15\n",
      "05-Amorphous       0.58      0.45      0.51       132\n",
      "\n",
      "    accuracy                           0.35       229\n",
      "   macro avg       0.22      0.23      0.22       229\n",
      "weighted avg       0.41      0.35      0.37       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ce80236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80de5d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.5139 - accuracy: 0.4659\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50667, saving model to /home/mcoronado/Escritorio/Models_VGG16_V3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 10s 210ms/step - loss: 1.5139 - accuracy: 0.4659 - val_loss: 1.0167 - val_accuracy: 0.5067 - lr: 3.1250e-05\n",
      "Epoch 2/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.3176 - accuracy: 0.4856\n",
      "Epoch 2: val_accuracy did not improve from 0.50667\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 1.3176 - accuracy: 0.4856 - val_loss: 1.0316 - val_accuracy: 0.5067 - lr: 3.1250e-05\n",
      "Epoch 3/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2727 - accuracy: 0.4876\n",
      "Epoch 3: val_accuracy improved from 0.50667 to 0.52000, saving model to /home/mcoronado/Escritorio/Models_VGG16_V3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 10s 212ms/step - loss: 1.2727 - accuracy: 0.4876 - val_loss: 1.0264 - val_accuracy: 0.5200 - lr: 3.1250e-05\n",
      "Epoch 4/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2366 - accuracy: 0.4944\n",
      "Epoch 4: val_accuracy did not improve from 0.52000\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 1.2366 - accuracy: 0.4944 - val_loss: 1.0276 - val_accuracy: 0.5200 - lr: 3.1250e-05\n",
      "Epoch 5/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1997 - accuracy: 0.5049\n",
      "Epoch 5: val_accuracy improved from 0.52000 to 0.53333, saving model to /home/mcoronado/Escritorio/Models_VGG16_V3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 10s 208ms/step - loss: 1.1997 - accuracy: 0.5049 - val_loss: 1.0325 - val_accuracy: 0.5333 - lr: 3.1250e-05\n",
      "Epoch 6/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2243 - accuracy: 0.4902\n",
      "Epoch 6: val_accuracy did not improve from 0.53333\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.2243 - accuracy: 0.4902 - val_loss: 1.0242 - val_accuracy: 0.5333 - lr: 3.1250e-05\n",
      "Epoch 7/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1959 - accuracy: 0.5007\n",
      "Epoch 7: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.1959 - accuracy: 0.5007 - val_loss: 1.0220 - val_accuracy: 0.5333 - lr: 1.5625e-05\n",
      "Epoch 8/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.2142 - accuracy: 0.4964\n",
      "Epoch 8: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 160ms/step - loss: 1.2142 - accuracy: 0.4964 - val_loss: 1.0267 - val_accuracy: 0.5067 - lr: 1.5625e-05\n",
      "Epoch 9/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1788 - accuracy: 0.4987\n",
      "Epoch 9: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.1788 - accuracy: 0.4987 - val_loss: 1.0291 - val_accuracy: 0.5333 - lr: 1.5625e-05\n",
      "Epoch 10/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1737 - accuracy: 0.5069\n",
      "Epoch 10: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 1.1737 - accuracy: 0.5069 - val_loss: 1.0262 - val_accuracy: 0.5333 - lr: 1.5625e-05\n",
      "Epoch 11/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1664 - accuracy: 0.5151\n",
      "Epoch 11: val_accuracy did not improve from 0.53333\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.1664 - accuracy: 0.5151 - val_loss: 1.0269 - val_accuracy: 0.5200 - lr: 1.5625e-05\n",
      "Epoch 12/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1682 - accuracy: 0.5174\n",
      "Epoch 12: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.1682 - accuracy: 0.5174 - val_loss: 1.0264 - val_accuracy: 0.5067 - lr: 7.8125e-06\n",
      "Epoch 13/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1607 - accuracy: 0.4967\n",
      "Epoch 13: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.1607 - accuracy: 0.4967 - val_loss: 1.0238 - val_accuracy: 0.5200 - lr: 7.8125e-06\n",
      "Epoch 14/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1660 - accuracy: 0.5160\n",
      "Epoch 14: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.1660 - accuracy: 0.5160 - val_loss: 1.0256 - val_accuracy: 0.5333 - lr: 7.8125e-06\n",
      "Epoch 15/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1639 - accuracy: 0.5121\n",
      "Epoch 15: val_accuracy did not improve from 0.53333\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 1.1639 - accuracy: 0.5121 - val_loss: 1.0252 - val_accuracy: 0.5333 - lr: 7.8125e-06\n",
      "Epoch 16/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1597 - accuracy: 0.5023\n",
      "Epoch 16: val_accuracy improved from 0.53333 to 0.54667, saving model to /home/mcoronado/Escritorio/Models_VGG16_V3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_VGG16_V3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "48/48 [==============================] - 11s 232ms/step - loss: 1.1597 - accuracy: 0.5023 - val_loss: 1.0260 - val_accuracy: 0.5467 - lr: 7.8125e-06\n",
      "Epoch 17/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1646 - accuracy: 0.5134\n",
      "Epoch 17: val_accuracy did not improve from 0.54667\n",
      "48/48 [==============================] - 8s 165ms/step - loss: 1.1646 - accuracy: 0.5134 - val_loss: 1.0262 - val_accuracy: 0.5467 - lr: 3.9063e-06\n",
      "Epoch 18/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1553 - accuracy: 0.5121\n",
      "Epoch 18: val_accuracy did not improve from 0.54667\n",
      "48/48 [==============================] - 8s 161ms/step - loss: 1.1553 - accuracy: 0.5121 - val_loss: 1.0265 - val_accuracy: 0.5467 - lr: 3.9063e-06\n",
      "Epoch 19/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1439 - accuracy: 0.5164\n",
      "Epoch 19: val_accuracy did not improve from 0.54667\n",
      "48/48 [==============================] - 8s 162ms/step - loss: 1.1439 - accuracy: 0.5164 - val_loss: 1.0275 - val_accuracy: 0.5333 - lr: 3.9063e-06\n",
      "Epoch 20/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1458 - accuracy: 0.5229\n",
      "Epoch 20: val_accuracy did not improve from 0.54667\n",
      "48/48 [==============================] - 9s 179ms/step - loss: 1.1458 - accuracy: 0.5229 - val_loss: 1.0265 - val_accuracy: 0.5467 - lr: 3.9063e-06\n",
      "Epoch 21/200\n",
      "48/48 [==============================] - ETA: 0s - loss: 1.1467 - accuracy: 0.5151\n",
      "Epoch 21: val_accuracy did not improve from 0.54667\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 1.1467 - accuracy: 0.5151 - val_loss: 1.0263 - val_accuracy: 0.5467 - lr: 3.9063e-06\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = crearCallBacks('/home/mcoronado/Escritorio/Models_VGG16_V3')\n",
    "model_history12 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9234fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 2s 9ms/step - loss: 1.2053 - accuracy: 0.4716\n",
      "Test loss: 1.2052791118621826\n",
      "Test accuracy: 0.471615731716156\n",
      "229/229 [==============================] - 2s 9ms/step\n",
      "[[ 5  3  3  2  7]\n",
      " [ 8  6  5  4 23]\n",
      " [ 3  4  1  2  6]\n",
      " [ 4  1  4  3  3]\n",
      " [24 11 31 13 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.11      0.25      0.16        20\n",
      "  02-Tapered       0.24      0.13      0.17        46\n",
      " 03-Pyriform       0.02      0.06      0.03        16\n",
      "    04-Small       0.12      0.20      0.15        15\n",
      "05-Amorphous       0.58      0.40      0.47       132\n",
      "\n",
      "    accuracy                           0.30       229\n",
      "   macro avg       0.22      0.21      0.20       229\n",
      "weighted avg       0.40      0.30      0.33       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d4df13c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14657/1028141915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdec345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26de9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ea9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancearConjuntoValidacion():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101aac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "5b4f93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn7 = crearCNN_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "130628d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14657/4076839833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87f0e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = crearCallBacks('/home/mcoronado/Escritorio/Models_AFGDDZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "556b6111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.4114 - accuracy: 0.3960\n",
      "Epoch 1: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 14s 163ms/step - loss: 1.4114 - accuracy: 0.3960 - val_loss: 1.2256 - val_accuracy: 0.5153 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.2176 - accuracy: 0.4968\n",
      "Epoch 2: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 13s 156ms/step - loss: 1.2176 - accuracy: 0.4968 - val_loss: 1.1802 - val_accuracy: 0.5022 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "35/82 [===========>..................] - ETA: 6s - loss: 1.1593 - accuracy: 0.5170"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14657/1149092154.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_history11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentrenarModelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14657/230583628.py\u001b[0m in \u001b[0;36mentrenarModelo\u001b[0;34m(modelo, epochs, train_data, valid_data, callbacks)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             callbacks = callbacks) \n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history11 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b679d596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8791 - accuracy: 0.6458\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56332, saving model to /home/mcoronado/Escritorio/Models_AFGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFGD/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFGD/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 22s 263ms/step - loss: 0.8791 - accuracy: 0.6458 - val_loss: 1.0408 - val_accuracy: 0.5633 - lr: 9.7656e-07\n",
      "Epoch 2/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8805 - accuracy: 0.6489\n",
      "Epoch 2: val_accuracy improved from 0.56332 to 0.56769, saving model to /home/mcoronado/Escritorio/Models_AFGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFGD/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFGD/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 23s 281ms/step - loss: 0.8805 - accuracy: 0.6489 - val_loss: 1.0386 - val_accuracy: 0.5677 - lr: 9.7656e-07\n",
      "Epoch 3/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8744 - accuracy: 0.6513\n",
      "Epoch 3: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.8744 - accuracy: 0.6513 - val_loss: 1.0403 - val_accuracy: 0.5633 - lr: 9.7656e-07\n",
      "Epoch 4/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8770 - accuracy: 0.6525\n",
      "Epoch 4: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 21s 252ms/step - loss: 0.8770 - accuracy: 0.6525 - val_loss: 1.0422 - val_accuracy: 0.5546 - lr: 9.7656e-07\n",
      "Epoch 5/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8779 - accuracy: 0.6576\n",
      "Epoch 5: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 0.8779 - accuracy: 0.6576 - val_loss: 1.0418 - val_accuracy: 0.5459 - lr: 9.7656e-07\n",
      "Epoch 6/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8719 - accuracy: 0.6576\n",
      "Epoch 6: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 0.8719 - accuracy: 0.6576 - val_loss: 1.0404 - val_accuracy: 0.5502 - lr: 9.7656e-07\n",
      "Epoch 7/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8742 - accuracy: 0.6511\n",
      "Epoch 7: val_accuracy did not improve from 0.56769\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "82/82 [==============================] - 20s 248ms/step - loss: 0.8742 - accuracy: 0.6511 - val_loss: 1.0424 - val_accuracy: 0.5502 - lr: 9.7656e-07\n",
      "Epoch 8/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8653 - accuracy: 0.6567\n",
      "Epoch 8: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.8653 - accuracy: 0.6567 - val_loss: 1.0418 - val_accuracy: 0.5502 - lr: 4.8828e-07\n",
      "Epoch 9/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8676 - accuracy: 0.6552\n",
      "Epoch 9: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.8676 - accuracy: 0.6552 - val_loss: 1.0421 - val_accuracy: 0.5502 - lr: 4.8828e-07\n",
      "Epoch 10/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8692 - accuracy: 0.6538\n",
      "Epoch 10: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.8692 - accuracy: 0.6538 - val_loss: 1.0413 - val_accuracy: 0.5502 - lr: 4.8828e-07\n",
      "Epoch 11/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8697 - accuracy: 0.6582\n",
      "Epoch 11: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 23s 279ms/step - loss: 0.8697 - accuracy: 0.6582 - val_loss: 1.0423 - val_accuracy: 0.5546 - lr: 4.8828e-07\n",
      "Epoch 12/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.6557\n",
      "Epoch 12: val_accuracy did not improve from 0.56769\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.8690 - accuracy: 0.6557 - val_loss: 1.0419 - val_accuracy: 0.5546 - lr: 4.8828e-07\n",
      "Epoch 13/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8803 - accuracy: 0.6473\n",
      "Epoch 13: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.8803 - accuracy: 0.6473 - val_loss: 1.0415 - val_accuracy: 0.5546 - lr: 2.4414e-07\n",
      "Epoch 14/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.6527\n",
      "Epoch 14: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.8705 - accuracy: 0.6527 - val_loss: 1.0408 - val_accuracy: 0.5546 - lr: 2.4414e-07\n",
      "Epoch 15/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8724 - accuracy: 0.6569\n",
      "Epoch 15: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.8724 - accuracy: 0.6569 - val_loss: 1.0416 - val_accuracy: 0.5546 - lr: 2.4414e-07\n",
      "Epoch 16/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8673 - accuracy: 0.6540\n",
      "Epoch 16: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.8673 - accuracy: 0.6540 - val_loss: 1.0405 - val_accuracy: 0.5459 - lr: 2.4414e-07\n",
      "Epoch 17/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8796 - accuracy: 0.6521\n",
      "Epoch 17: val_accuracy did not improve from 0.56769\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.8796 - accuracy: 0.6521 - val_loss: 1.0408 - val_accuracy: 0.5502 - lr: 2.4414e-07\n",
      "Epoch 18/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8761 - accuracy: 0.6536\n",
      "Epoch 18: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.8761 - accuracy: 0.6536 - val_loss: 1.0414 - val_accuracy: 0.5502 - lr: 1.2207e-07\n",
      "Epoch 19/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8717 - accuracy: 0.6540\n",
      "Epoch 19: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 0.8717 - accuracy: 0.6540 - val_loss: 1.0416 - val_accuracy: 0.5502 - lr: 1.2207e-07\n",
      "Epoch 20/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8672 - accuracy: 0.6594\n",
      "Epoch 20: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.8672 - accuracy: 0.6594 - val_loss: 1.0416 - val_accuracy: 0.5502 - lr: 1.2207e-07\n",
      "Epoch 21/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8728 - accuracy: 0.6597\n",
      "Epoch 21: val_accuracy did not improve from 0.56769\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.8728 - accuracy: 0.6597 - val_loss: 1.0416 - val_accuracy: 0.5502 - lr: 1.2207e-07\n",
      "Epoch 22/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8673 - accuracy: 0.6546\n",
      "Epoch 22: val_accuracy did not improve from 0.56769\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 0.8673 - accuracy: 0.6546 - val_loss: 1.0418 - val_accuracy: 0.5502 - lr: 1.2207e-07\n",
      "Epoch 22: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_history10 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b0fdef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1818 - accuracy: 0.5074\n",
      "Epoch 1: val_accuracy improved from -inf to 0.44105, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 23s 277ms/step - loss: 1.1818 - accuracy: 0.5074 - val_loss: 1.2016 - val_accuracy: 0.4410 - lr: 3.1250e-05\n",
      "Epoch 2/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1397 - accuracy: 0.5323\n",
      "Epoch 2: val_accuracy did not improve from 0.44105\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 1.1397 - accuracy: 0.5323 - val_loss: 1.2365 - val_accuracy: 0.4192 - lr: 3.1250e-05\n",
      "Epoch 3/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1274 - accuracy: 0.5336\n",
      "Epoch 3: val_accuracy did not improve from 0.44105\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 1.1274 - accuracy: 0.5336 - val_loss: 1.1989 - val_accuracy: 0.4367 - lr: 3.1250e-05\n",
      "Epoch 4/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.1069 - accuracy: 0.5494\n",
      "Epoch 4: val_accuracy did not improve from 0.44105\n",
      "82/82 [==============================] - 21s 254ms/step - loss: 1.1069 - accuracy: 0.5494 - val_loss: 1.2265 - val_accuracy: 0.4323 - lr: 3.1250e-05\n",
      "Epoch 5/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0936 - accuracy: 0.5469\n",
      "Epoch 5: val_accuracy improved from 0.44105 to 0.44978, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 24s 294ms/step - loss: 1.0936 - accuracy: 0.5469 - val_loss: 1.1701 - val_accuracy: 0.4498 - lr: 3.1250e-05\n",
      "Epoch 6/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0828 - accuracy: 0.5573\n",
      "Epoch 6: val_accuracy improved from 0.44978 to 0.48472, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 24s 291ms/step - loss: 1.0828 - accuracy: 0.5573 - val_loss: 1.1611 - val_accuracy: 0.4847 - lr: 3.1250e-05\n",
      "Epoch 7/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0579 - accuracy: 0.5685\n",
      "Epoch 7: val_accuracy did not improve from 0.48472\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 1.0579 - accuracy: 0.5685 - val_loss: 1.1298 - val_accuracy: 0.4847 - lr: 3.1250e-05\n",
      "Epoch 8/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0390 - accuracy: 0.5781\n",
      "Epoch 8: val_accuracy improved from 0.48472 to 0.49345, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 24s 292ms/step - loss: 1.0390 - accuracy: 0.5781 - val_loss: 1.1322 - val_accuracy: 0.4934 - lr: 3.1250e-05\n",
      "Epoch 9/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0425 - accuracy: 0.5761\n",
      "Epoch 9: val_accuracy improved from 0.49345 to 0.52838, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 24s 289ms/step - loss: 1.0425 - accuracy: 0.5761 - val_loss: 1.0907 - val_accuracy: 0.5284 - lr: 3.1250e-05\n",
      "Epoch 10/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.5739\n",
      "Epoch 10: val_accuracy did not improve from 0.52838\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 1.0350 - accuracy: 0.5739 - val_loss: 1.0938 - val_accuracy: 0.5066 - lr: 3.1250e-05\n",
      "Epoch 11/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0177 - accuracy: 0.5811\n",
      "Epoch 11: val_accuracy did not improve from 0.52838\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 1.0177 - accuracy: 0.5811 - val_loss: 1.0987 - val_accuracy: 0.5109 - lr: 3.1250e-05\n",
      "Epoch 12/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0172 - accuracy: 0.5819\n",
      "Epoch 12: val_accuracy did not improve from 0.52838\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 1.0172 - accuracy: 0.5819 - val_loss: 1.0778 - val_accuracy: 0.5197 - lr: 3.1250e-05\n",
      "Epoch 13/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0129 - accuracy: 0.5891\n",
      "Epoch 13: val_accuracy improved from 0.52838 to 0.53712, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 24s 288ms/step - loss: 1.0129 - accuracy: 0.5891 - val_loss: 1.0579 - val_accuracy: 0.5371 - lr: 3.1250e-05\n",
      "Epoch 14/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 1.0086 - accuracy: 0.5832\n",
      "Epoch 14: val_accuracy did not improve from 0.53712\n",
      "82/82 [==============================] - 21s 259ms/step - loss: 1.0086 - accuracy: 0.5832 - val_loss: 1.2067 - val_accuracy: 0.4585 - lr: 3.1250e-05\n",
      "Epoch 15/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9798 - accuracy: 0.6074\n",
      "Epoch 15: val_accuracy did not improve from 0.53712\n",
      "82/82 [==============================] - 22s 263ms/step - loss: 0.9798 - accuracy: 0.6074 - val_loss: 1.0622 - val_accuracy: 0.5328 - lr: 3.1250e-05\n",
      "Epoch 16/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9764 - accuracy: 0.6090\n",
      "Epoch 16: val_accuracy did not improve from 0.53712\n",
      "82/82 [==============================] - 21s 255ms/step - loss: 0.9764 - accuracy: 0.6090 - val_loss: 1.0971 - val_accuracy: 0.5066 - lr: 3.1250e-05\n",
      "Epoch 17/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.6017\n",
      "Epoch 17: val_accuracy did not improve from 0.53712\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9747 - accuracy: 0.6017 - val_loss: 1.0698 - val_accuracy: 0.5328 - lr: 3.1250e-05\n",
      "Epoch 18/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9738 - accuracy: 0.6017\n",
      "Epoch 18: val_accuracy did not improve from 0.53712\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9738 - accuracy: 0.6017 - val_loss: 1.0993 - val_accuracy: 0.5066 - lr: 3.1250e-05\n",
      "Epoch 19/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9568 - accuracy: 0.6061\n",
      "Epoch 19: val_accuracy did not improve from 0.53712\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.9568 - accuracy: 0.6061 - val_loss: 1.0642 - val_accuracy: 0.5328 - lr: 1.5625e-05\n",
      "Epoch 20/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9463 - accuracy: 0.6181\n",
      "Epoch 20: val_accuracy did not improve from 0.53712\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.9463 - accuracy: 0.6181 - val_loss: 1.0807 - val_accuracy: 0.5240 - lr: 1.5625e-05\n",
      "Epoch 21/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9516 - accuracy: 0.6156\n",
      "Epoch 21: val_accuracy improved from 0.53712 to 0.55895, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 24s 290ms/step - loss: 0.9516 - accuracy: 0.6156 - val_loss: 1.0502 - val_accuracy: 0.5590 - lr: 1.5625e-05\n",
      "Epoch 22/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9371 - accuracy: 0.6227\n",
      "Epoch 22: val_accuracy did not improve from 0.55895\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9371 - accuracy: 0.6227 - val_loss: 1.0899 - val_accuracy: 0.5153 - lr: 1.5625e-05\n",
      "Epoch 23/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9355 - accuracy: 0.6250\n",
      "Epoch 23: val_accuracy did not improve from 0.55895\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.9355 - accuracy: 0.6250 - val_loss: 1.0958 - val_accuracy: 0.5153 - lr: 1.5625e-05\n",
      "Epoch 24/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9346 - accuracy: 0.6248\n",
      "Epoch 24: val_accuracy did not improve from 0.55895\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9346 - accuracy: 0.6248 - val_loss: 1.0487 - val_accuracy: 0.5415 - lr: 1.5625e-05\n",
      "Epoch 25/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9325 - accuracy: 0.6183\n",
      "Epoch 25: val_accuracy did not improve from 0.55895\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.9325 - accuracy: 0.6183 - val_loss: 1.0490 - val_accuracy: 0.5502 - lr: 1.5625e-05\n",
      "Epoch 26/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9233 - accuracy: 0.6250\n",
      "Epoch 26: val_accuracy improved from 0.55895 to 0.57642, saving model to /home/mcoronado/Escritorio/Models_AFG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AFG/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 24s 290ms/step - loss: 0.9233 - accuracy: 0.6250 - val_loss: 1.0167 - val_accuracy: 0.5764 - lr: 1.5625e-05\n",
      "Epoch 27/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9270 - accuracy: 0.6305\n",
      "Epoch 27: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 248ms/step - loss: 0.9270 - accuracy: 0.6305 - val_loss: 1.0691 - val_accuracy: 0.5415 - lr: 1.5625e-05\n",
      "Epoch 28/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.6389\n",
      "Epoch 28: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9066 - accuracy: 0.6389 - val_loss: 1.0696 - val_accuracy: 0.5459 - lr: 1.5625e-05\n",
      "Epoch 29/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9049 - accuracy: 0.6405\n",
      "Epoch 29: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9049 - accuracy: 0.6405 - val_loss: 1.0721 - val_accuracy: 0.5328 - lr: 1.5625e-05\n",
      "Epoch 30/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9098 - accuracy: 0.6300\n",
      "Epoch 30: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 249ms/step - loss: 0.9098 - accuracy: 0.6300 - val_loss: 1.0893 - val_accuracy: 0.5109 - lr: 1.5625e-05\n",
      "Epoch 31/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9179 - accuracy: 0.6302\n",
      "Epoch 31: val_accuracy did not improve from 0.57642\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "82/82 [==============================] - 21s 251ms/step - loss: 0.9179 - accuracy: 0.6302 - val_loss: 1.0859 - val_accuracy: 0.5066 - lr: 1.5625e-05\n",
      "Epoch 32/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9102 - accuracy: 0.6290\n",
      "Epoch 32: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.9102 - accuracy: 0.6290 - val_loss: 1.0699 - val_accuracy: 0.5197 - lr: 7.8125e-06\n",
      "Epoch 33/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9027 - accuracy: 0.6376\n",
      "Epoch 33: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9027 - accuracy: 0.6376 - val_loss: 1.0681 - val_accuracy: 0.5371 - lr: 7.8125e-06\n",
      "Epoch 34/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8903 - accuracy: 0.6385\n",
      "Epoch 34: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.8903 - accuracy: 0.6385 - val_loss: 1.0591 - val_accuracy: 0.5371 - lr: 7.8125e-06\n",
      "Epoch 35/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8881 - accuracy: 0.6384\n",
      "Epoch 35: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 248ms/step - loss: 0.8881 - accuracy: 0.6384 - val_loss: 1.0738 - val_accuracy: 0.5284 - lr: 7.8125e-06\n",
      "Epoch 36/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9012 - accuracy: 0.6363\n",
      "Epoch 36: val_accuracy did not improve from 0.57642\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.9012 - accuracy: 0.6363 - val_loss: 1.0625 - val_accuracy: 0.5284 - lr: 7.8125e-06\n",
      "Epoch 37/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8904 - accuracy: 0.6466\n",
      "Epoch 37: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.8904 - accuracy: 0.6466 - val_loss: 1.0518 - val_accuracy: 0.5502 - lr: 3.9063e-06\n",
      "Epoch 38/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9061 - accuracy: 0.6336\n",
      "Epoch 38: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9061 - accuracy: 0.6336 - val_loss: 1.0440 - val_accuracy: 0.5633 - lr: 3.9063e-06\n",
      "Epoch 39/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8911 - accuracy: 0.6403\n",
      "Epoch 39: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 253ms/step - loss: 0.8911 - accuracy: 0.6403 - val_loss: 1.0422 - val_accuracy: 0.5590 - lr: 3.9063e-06\n",
      "Epoch 40/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8710 - accuracy: 0.6525\n",
      "Epoch 40: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 255ms/step - loss: 0.8710 - accuracy: 0.6525 - val_loss: 1.0566 - val_accuracy: 0.5415 - lr: 3.9063e-06\n",
      "Epoch 41/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8996 - accuracy: 0.6399\n",
      "Epoch 41: val_accuracy did not improve from 0.57642\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.8996 - accuracy: 0.6399 - val_loss: 1.0548 - val_accuracy: 0.5502 - lr: 3.9063e-06\n",
      "Epoch 42/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8756 - accuracy: 0.6468\n",
      "Epoch 42: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 252ms/step - loss: 0.8756 - accuracy: 0.6468 - val_loss: 1.0523 - val_accuracy: 0.5459 - lr: 1.9531e-06\n",
      "Epoch 43/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8977 - accuracy: 0.6426\n",
      "Epoch 43: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.8977 - accuracy: 0.6426 - val_loss: 1.0512 - val_accuracy: 0.5415 - lr: 1.9531e-06\n",
      "Epoch 44/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.9009 - accuracy: 0.6418\n",
      "Epoch 44: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.9009 - accuracy: 0.6418 - val_loss: 1.0608 - val_accuracy: 0.5284 - lr: 1.9531e-06\n",
      "Epoch 45/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8828 - accuracy: 0.6481\n",
      "Epoch 45: val_accuracy did not improve from 0.57642\n",
      "82/82 [==============================] - 21s 250ms/step - loss: 0.8828 - accuracy: 0.6481 - val_loss: 1.0583 - val_accuracy: 0.5371 - lr: 1.9531e-06\n",
      "Epoch 46/200\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.8932 - accuracy: 0.6498\n",
      "Epoch 46: val_accuracy did not improve from 0.57642\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "82/82 [==============================] - 21s 249ms/step - loss: 0.8932 - accuracy: 0.6498 - val_loss: 1.0506 - val_accuracy: 0.5590 - lr: 1.9531e-06\n",
      "Epoch 46: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_history9 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d999b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce7060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd294ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 3s 11ms/step - loss: 1.0573 - accuracy: 0.5197\n",
      "Test loss: 1.0572887659072876\n",
      "Test accuracy: 0.5196506381034851\n",
      "229/229 [==============================] - 2s 10ms/step\n",
      "[[ 4  3  4  2  7]\n",
      " [ 3  9  5  5 24]\n",
      " [ 3  2  2  2  7]\n",
      " [ 1  3  1  2  8]\n",
      " [15 35 15 12 55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.15      0.20      0.17        20\n",
      "  02-Tapered       0.17      0.20      0.18        46\n",
      " 03-Pyriform       0.07      0.12      0.09        16\n",
      "    04-Small       0.09      0.13      0.11        15\n",
      "05-Amorphous       0.54      0.42      0.47       132\n",
      "\n",
      "    accuracy                           0.31       229\n",
      "   macro avg       0.21      0.21      0.21       229\n",
      "weighted avg       0.37      0.31      0.34       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "762a4788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.8114 - accuracy: 0.5134\n",
      "Epoch 1: val_accuracy did not improve from 0.58515\n",
      "11/11 [==============================] - 4s 313ms/step - loss: 1.8114 - accuracy: 0.5134 - val_loss: 1.2306 - val_accuracy: 0.5764 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1807 - accuracy: 0.5890\n",
      "Epoch 2: val_accuracy improved from 0.58515 to 0.59825, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 612ms/step - loss: 1.1807 - accuracy: 0.5890 - val_loss: 1.0972 - val_accuracy: 0.5983 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0824 - accuracy: 0.6039\n",
      "Epoch 3: val_accuracy improved from 0.59825 to 0.60699, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 645ms/step - loss: 1.0824 - accuracy: 0.6039 - val_loss: 1.0447 - val_accuracy: 0.6070 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1033 - accuracy: 0.5801\n",
      "Epoch 4: val_accuracy improved from 0.60699 to 0.61135, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 611ms/step - loss: 1.1033 - accuracy: 0.5801 - val_loss: 1.0280 - val_accuracy: 0.6114 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0783 - accuracy: 0.5935\n",
      "Epoch 5: val_accuracy did not improve from 0.61135\n",
      "11/11 [==============================] - 3s 296ms/step - loss: 1.0783 - accuracy: 0.5935 - val_loss: 1.0070 - val_accuracy: 0.5983 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.6187\n",
      "Epoch 6: val_accuracy did not improve from 0.61135\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 1.0271 - accuracy: 0.6187 - val_loss: 0.9854 - val_accuracy: 0.6070 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.6335\n",
      "Epoch 7: val_accuracy did not improve from 0.61135\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 0.9900 - accuracy: 0.6335 - val_loss: 1.0163 - val_accuracy: 0.5983 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0202 - accuracy: 0.5890\n",
      "Epoch 8: val_accuracy did not improve from 0.61135\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 1.0202 - accuracy: 0.5890 - val_loss: 1.0162 - val_accuracy: 0.6070 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0245 - accuracy: 0.6202\n",
      "Epoch 9: val_accuracy improved from 0.61135 to 0.62009, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 642ms/step - loss: 1.0245 - accuracy: 0.6202 - val_loss: 0.9736 - val_accuracy: 0.6201 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0018 - accuracy: 0.6306\n",
      "Epoch 10: val_accuracy improved from 0.62009 to 0.62445, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 608ms/step - loss: 1.0018 - accuracy: 0.6306 - val_loss: 0.9553 - val_accuracy: 0.6245 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.6380\n",
      "Epoch 11: val_accuracy did not improve from 0.62445\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 0.9555 - accuracy: 0.6380 - val_loss: 0.9353 - val_accuracy: 0.6245 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9837 - accuracy: 0.6395\n",
      "Epoch 12: val_accuracy improved from 0.62445 to 0.62882, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 629ms/step - loss: 0.9837 - accuracy: 0.6395 - val_loss: 0.9610 - val_accuracy: 0.6288 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9597 - accuracy: 0.6187\n",
      "Epoch 13: val_accuracy did not improve from 0.62882\n",
      "11/11 [==============================] - 3s 288ms/step - loss: 0.9597 - accuracy: 0.6187 - val_loss: 1.0314 - val_accuracy: 0.6070 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.6409\n",
      "Epoch 14: val_accuracy did not improve from 0.62882\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 0.9588 - accuracy: 0.6409 - val_loss: 0.9403 - val_accuracy: 0.6114 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9916 - accuracy: 0.5979\n",
      "Epoch 15: val_accuracy did not improve from 0.62882\n",
      "11/11 [==============================] - 3s 306ms/step - loss: 0.9916 - accuracy: 0.5979 - val_loss: 0.9581 - val_accuracy: 0.6201 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9732 - accuracy: 0.6409\n",
      "Epoch 16: val_accuracy did not improve from 0.62882\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "11/11 [==============================] - 3s 294ms/step - loss: 0.9732 - accuracy: 0.6409 - val_loss: 0.9496 - val_accuracy: 0.6245 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.6573\n",
      "Epoch 17: val_accuracy did not improve from 0.62882\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.9237 - accuracy: 0.6573 - val_loss: 0.9813 - val_accuracy: 0.6070 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9355 - accuracy: 0.6320\n",
      "Epoch 18: val_accuracy did not improve from 0.62882\n",
      "11/11 [==============================] - 3s 304ms/step - loss: 0.9355 - accuracy: 0.6320 - val_loss: 0.9280 - val_accuracy: 0.6245 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8883 - accuracy: 0.6528\n",
      "Epoch 19: val_accuracy improved from 0.62882 to 0.63319, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 625ms/step - loss: 0.8883 - accuracy: 0.6528 - val_loss: 0.9169 - val_accuracy: 0.6332 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8865 - accuracy: 0.6484\n",
      "Epoch 20: val_accuracy did not improve from 0.63319\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 0.8865 - accuracy: 0.6484 - val_loss: 0.9211 - val_accuracy: 0.6245 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9302 - accuracy: 0.6335\n",
      "Epoch 21: val_accuracy did not improve from 0.63319\n",
      "11/11 [==============================] - 3s 303ms/step - loss: 0.9302 - accuracy: 0.6335 - val_loss: 0.9390 - val_accuracy: 0.6201 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9274 - accuracy: 0.6320\n",
      "Epoch 22: val_accuracy improved from 0.63319 to 0.64192, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 645ms/step - loss: 0.9274 - accuracy: 0.6320 - val_loss: 0.9435 - val_accuracy: 0.6419 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9258 - accuracy: 0.6469\n",
      "Epoch 23: val_accuracy did not improve from 0.64192\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 0.9258 - accuracy: 0.6469 - val_loss: 0.9654 - val_accuracy: 0.6114 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8535 - accuracy: 0.6632\n",
      "Epoch 24: val_accuracy did not improve from 0.64192\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.8535 - accuracy: 0.6632 - val_loss: 0.9852 - val_accuracy: 0.5939 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.6365\n",
      "Epoch 25: val_accuracy did not improve from 0.64192\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.8861 - accuracy: 0.6365 - val_loss: 0.9437 - val_accuracy: 0.6332 - lr: 2.5000e-04\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8558 - accuracy: 0.6573\n",
      "Epoch 26: val_accuracy did not improve from 0.64192\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 0.8558 - accuracy: 0.6573 - val_loss: 0.9713 - val_accuracy: 0.5808 - lr: 2.5000e-04\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.6499\n",
      "Epoch 27: val_accuracy did not improve from 0.64192\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 0.8701 - accuracy: 0.6499 - val_loss: 0.9749 - val_accuracy: 0.5983 - lr: 2.5000e-04\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8728 - accuracy: 0.6484\n",
      "Epoch 28: val_accuracy did not improve from 0.64192\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 0.8728 - accuracy: 0.6484 - val_loss: 0.9291 - val_accuracy: 0.6419 - lr: 2.5000e-04\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8556 - accuracy: 0.6499\n",
      "Epoch 29: val_accuracy did not improve from 0.64192\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 0.8556 - accuracy: 0.6499 - val_loss: 0.9323 - val_accuracy: 0.6419 - lr: 2.5000e-04\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.6573\n",
      "Epoch 30: val_accuracy improved from 0.64192 to 0.64629, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 607ms/step - loss: 0.8530 - accuracy: 0.6573 - val_loss: 0.9309 - val_accuracy: 0.6463 - lr: 1.2500e-04\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.6558\n",
      "Epoch 31: val_accuracy did not improve from 0.64629\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 0.8548 - accuracy: 0.6558 - val_loss: 0.9341 - val_accuracy: 0.6419 - lr: 1.2500e-04\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8562 - accuracy: 0.6528\n",
      "Epoch 32: val_accuracy did not improve from 0.64629\n",
      "11/11 [==============================] - 3s 301ms/step - loss: 0.8562 - accuracy: 0.6528 - val_loss: 0.9496 - val_accuracy: 0.6114 - lr: 1.2500e-04\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8233 - accuracy: 0.6588\n",
      "Epoch 33: val_accuracy improved from 0.64629 to 0.65066, saving model to /home/mcoronado/Escritorio/Models_AF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AF/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 663ms/step - loss: 0.8233 - accuracy: 0.6588 - val_loss: 0.9340 - val_accuracy: 0.6507 - lr: 1.2500e-04\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8317 - accuracy: 0.6484\n",
      "Epoch 34: val_accuracy did not improve from 0.65066\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "11/11 [==============================] - 3s 294ms/step - loss: 0.8317 - accuracy: 0.6484 - val_loss: 0.9360 - val_accuracy: 0.6463 - lr: 1.2500e-04\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8487 - accuracy: 0.6424\n",
      "Epoch 35: val_accuracy did not improve from 0.65066\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 0.8487 - accuracy: 0.6424 - val_loss: 0.9325 - val_accuracy: 0.6376 - lr: 6.2500e-05\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8486 - accuracy: 0.6424\n",
      "Epoch 36: val_accuracy did not improve from 0.65066\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 0.8486 - accuracy: 0.6424 - val_loss: 0.9365 - val_accuracy: 0.6157 - lr: 6.2500e-05\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8192 - accuracy: 0.6736\n",
      "Epoch 37: val_accuracy did not improve from 0.65066\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.8192 - accuracy: 0.6736 - val_loss: 0.9412 - val_accuracy: 0.6070 - lr: 6.2500e-05\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8124 - accuracy: 0.6662\n",
      "Epoch 38: val_accuracy did not improve from 0.65066\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 0.8124 - accuracy: 0.6662 - val_loss: 0.9295 - val_accuracy: 0.6157 - lr: 6.2500e-05\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8216 - accuracy: 0.6543\n",
      "Epoch 39: val_accuracy did not improve from 0.65066\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "11/11 [==============================] - 3s 303ms/step - loss: 0.8216 - accuracy: 0.6543 - val_loss: 0.9328 - val_accuracy: 0.6157 - lr: 6.2500e-05\n",
      "Epoch 39: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_history8 = entrenarModelo(vgg16_model, 200, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f4a525d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 3s 11ms/step - loss: 0.9563 - accuracy: 0.6245\n",
      "Test loss: 0.9562990665435791\n",
      "Test accuracy: 0.624454140663147\n",
      "229/229 [==============================] - 3s 10ms/step\n",
      "[[ 0  3  0  0 17]\n",
      " [ 1  8  0  0 37]\n",
      " [ 0  2  1  0 13]\n",
      " [ 0  4  0  0 11]\n",
      " [ 2 31  5  0 94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.00      0.00      0.00        20\n",
      "  02-Tapered       0.17      0.17      0.17        46\n",
      " 03-Pyriform       0.17      0.06      0.09        16\n",
      "    04-Small       0.00      0.00      0.00        15\n",
      "05-Amorphous       0.55      0.71      0.62       132\n",
      "\n",
      "    accuracy                           0.45       229\n",
      "   macro avg       0.18      0.19      0.18       229\n",
      "weighted avg       0.36      0.45      0.40       229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c62f2415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 3s 11ms/step - loss: 0.9545 - accuracy: 0.6332\n",
      "Test loss: 0.9544586539268494\n",
      "Test accuracy: 0.6331877708435059\n",
      "229/229 [==============================] - 3s 10ms/step\n",
      "[[  0   5   0   0  15]\n",
      " [  0   7   1   0  38]\n",
      " [  0   2   0   0  14]\n",
      " [  0   2   0   0  13]\n",
      " [  0  13   2   0 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.00      0.00      0.00        20\n",
      "  02-Tapered       0.24      0.15      0.19        46\n",
      " 03-Pyriform       0.00      0.00      0.00        16\n",
      "    04-Small       0.00      0.00      0.00        15\n",
      "05-Amorphous       0.59      0.89      0.71       132\n",
      "\n",
      "    accuracy                           0.54       229\n",
      "   macro avg       0.17      0.21      0.18       229\n",
      "weighted avg       0.39      0.54      0.45       229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae044ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 1s 6ms/step - loss: 0.8831 - accuracy: 0.6381\n",
      "Test loss: 0.8830553293228149\n",
      "Test accuracy: 0.6380952596664429\n",
      "105/105 [==============================] - 1s 6ms/step\n",
      "[[ 1  4  0  1  4]\n",
      " [ 4  2  1  3 11]\n",
      " [ 1  3  0  1  2]\n",
      " [ 1  1  0  1  4]\n",
      " [12 10  2  4 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.05      0.10      0.07        10\n",
      "  02-Tapered       0.10      0.10      0.10        21\n",
      " 03-Pyriform       0.00      0.00      0.00         7\n",
      "    04-Small       0.10      0.14      0.12         7\n",
      "05-Amorphous       0.60      0.53      0.57        60\n",
      "\n",
      "    accuracy                           0.34       105\n",
      "   macro avg       0.17      0.17      0.17       105\n",
      "weighted avg       0.38      0.34      0.36       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(cnn, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a25c5137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 1s 6ms/step - loss: 1.5987 - accuracy: 0.2000\n",
      "Test loss: 1.5987111330032349\n",
      "Test accuracy: 0.20000000298023224\n",
      "105/105 [==============================] - 1s 6ms/step\n",
      "[[ 0  2  0  2  6]\n",
      " [ 2  2  1  1 15]\n",
      " [ 2  1  0  1  3]\n",
      " [ 1  0  1  0  5]\n",
      " [ 7  7  4  4 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.00      0.00      0.00        10\n",
      "  02-Tapered       0.17      0.10      0.12        21\n",
      " 03-Pyriform       0.00      0.00      0.00         7\n",
      "    04-Small       0.00      0.00      0.00         7\n",
      "05-Amorphous       0.57      0.63      0.60        60\n",
      "\n",
      "    accuracy                           0.38       105\n",
      "   macro avg       0.15      0.15      0.14       105\n",
      "weighted avg       0.36      0.38      0.37       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(cnn1, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "727a9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_2\n",
      "2\n",
      "/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_3\n",
      "3\n",
      "/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_4\n",
      "4\n",
      "/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_5\n",
      "Initialised with 20 image(s) found.\n",
      "Output directory set to /home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_1/01-Normal/output.Initialised with 46 image(s) found.\n",
      "Output directory set to /home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_1/02-Tapered/output.Initialised with 16 image(s) found.\n",
      "Output directory set to /home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_1/03-Pyriform/output.Initialised with 15 image(s) found.\n",
      "Output directory set to /home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_1/04-Small/output.Initialised with 132 image(s) found.\n",
      "Output directory set to /home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/fold_1/05-Amorphous/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.TiffImagePlugin.TiffImageFile image mode=L size=35x35 at 0x7F56E\n",
      "Processing <PIL.Image.Image image mode=L size=35x35 at 0x7F56F4339510>: 100%|█| \n",
      "Processing <PIL.TiffImagePlugin.TiffImageFile image mode=L size=34x34 at 0x7F56E\n",
      "Processing <PIL.Image.Image image mode=L size=33x33 at 0x7F56F5CCFE50>: 100%|█| \n",
      "Processing <PIL.TiffImagePlugin.TiffImageFile image mode=L size=35x35 at 0x7F56E\n"
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "list_kfold_paths = generate_kFold_partitionImages( original_dir='/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/data/',\n",
    "                               dest_dir='/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/fold_data/',\n",
    "                               k_folds= k_folds)\n",
    "\n",
    "k_fold_dataAugmentation( 1 ,list_kfold_paths,5000)\n",
    "#k_fold_dataAugmentation_delete( 1 ,list_kfold_paths)\n",
    "\n",
    "\n",
    "aumentarImagenesSCIAN( list_kfold_paths[0] ,1000 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d2eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "54dec89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 6ms/step - loss: 1.5988 - accuracy: 0.2000\n",
      "Test loss: 1.598849892616272\n",
      "Test accuracy: 0.20000000298023224\n",
      "115/115 [==============================] - 1s 6ms/step\n",
      "[[ 1  2  0  0  7]\n",
      " [ 3  2  4  0 14]\n",
      " [ 0  0  1  1  6]\n",
      " [ 1  2  0  0  5]\n",
      " [ 6 10  1  1 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.09      0.10      0.10        10\n",
      "  02-Tapered       0.12      0.09      0.10        23\n",
      " 03-Pyriform       0.17      0.12      0.14         8\n",
      "    04-Small       0.00      0.00      0.00         8\n",
      "05-Amorphous       0.60      0.73      0.66        66\n",
      "\n",
      "    accuracy                           0.45       115\n",
      "   macro avg       0.20      0.21      0.20       115\n",
      "weighted avg       0.39      0.45      0.42       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(cnn2, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "37587077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.5437 - accuracy: 0.3274 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.31441, saving model to /home/mcoronado/Escritorio/Models_AC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AC/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_AC/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1289s 53s/step - loss: 1.5437 - accuracy: 0.3274 - val_loss: 1.5504 - val_accuracy: 0.3144 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "11/25 [============>.................] - ETA: 4:35 - loss: 1.2955 - accuracy: 0.4589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26418/4157095446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_history9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentrenarModelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_26418/230583628.py\u001b[0m in \u001b[0;36mentrenarModelo\u001b[0;34m(modelo, epochs, train_data, valid_data, callbacks)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             callbacks = callbacks) \n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2497\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1863\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history9 = entrenarModelo(cnn7, 50, train, valid, callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9a988fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4f8f8612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 6ms/step - loss: 1.5984 - accuracy: 0.2000\n",
      "Test loss: 1.5983712673187256\n",
      "Test accuracy: 0.20000000298023224\n",
      "115/115 [==============================] - 1s 6ms/step\n",
      "[[ 2  3  0  4  1]\n",
      " [ 2  5  3  4  9]\n",
      " [ 0  7  0  0  1]\n",
      " [ 4  1  1  0  2]\n",
      " [12 17  9  5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.10      0.20      0.13        10\n",
      "  02-Tapered       0.15      0.22      0.18        23\n",
      " 03-Pyriform       0.00      0.00      0.00         8\n",
      "    04-Small       0.00      0.00      0.00         8\n",
      "05-Amorphous       0.64      0.35      0.45        66\n",
      "\n",
      "    accuracy                           0.26       115\n",
      "   macro avg       0.18      0.15      0.15       115\n",
      "weighted avg       0.41      0.26      0.31       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(cnn3, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "8eee41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 6ms/step - loss: 1.5991 - accuracy: 0.2000\n",
      "Test loss: 1.5991137027740479\n",
      "Test accuracy: 0.20000000298023224\n",
      "115/115 [==============================] - 1s 6ms/step\n",
      "[[ 3  2  2  0  3]\n",
      " [ 3  6  3  1 10]\n",
      " [ 0  2  3  0  3]\n",
      " [ 1  2  1  1  3]\n",
      " [ 9 20  9  2 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.19      0.30      0.23        10\n",
      "  02-Tapered       0.19      0.26      0.22        23\n",
      " 03-Pyriform       0.17      0.38      0.23         8\n",
      "    04-Small       0.25      0.12      0.17         8\n",
      "05-Amorphous       0.58      0.39      0.47        66\n",
      "\n",
      "    accuracy                           0.34       115\n",
      "   macro avg       0.27      0.29      0.26       115\n",
      "weighted avg       0.41      0.34      0.36       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(cnn4, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "d2babe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 1s 6ms/step - loss: 1.5986 - accuracy: 0.2009\n",
      "Test loss: 1.5986082553863525\n",
      "Test accuracy: 0.20087336003780365\n",
      "229/229 [==============================] - 1s 6ms/step\n",
      "[[ 2  2  3  2 11]\n",
      " [ 9  6  3  2 26]\n",
      " [ 2  4  3  1  6]\n",
      " [ 3  2  2  0  8]\n",
      " [22 21 10  3 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.05      0.10      0.07        20\n",
      "  02-Tapered       0.17      0.13      0.15        46\n",
      " 03-Pyriform       0.14      0.19      0.16        16\n",
      "    04-Small       0.00      0.00      0.00        15\n",
      "05-Amorphous       0.60      0.58      0.59       132\n",
      "\n",
      "    accuracy                           0.38       229\n",
      "   macro avg       0.19      0.20      0.19       229\n",
      "weighted avg       0.39      0.38      0.39       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(cnn5, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "966c4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 1s 6ms/step - loss: 1.5993 - accuracy: 0.2052\n",
      "Test loss: 1.5993350744247437\n",
      "Test accuracy: 0.2052401751279831\n",
      "229/229 [==============================] - 2s 6ms/step\n",
      "[[ 0  8  1  1 10]\n",
      " [ 1  8  2  1 34]\n",
      " [ 1  6  1  0  8]\n",
      " [ 0  4  0  0 11]\n",
      " [15 30  6 10 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.00      0.00      0.00        20\n",
      "  02-Tapered       0.14      0.17      0.16        46\n",
      " 03-Pyriform       0.10      0.06      0.08        16\n",
      "    04-Small       0.00      0.00      0.00        15\n",
      "05-Amorphous       0.53      0.54      0.53       132\n",
      "\n",
      "    accuracy                           0.35       229\n",
      "   macro avg       0.15      0.15      0.15       229\n",
      "weighted avg       0.34      0.35      0.34       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(cnn6, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "8319157d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 2s 9ms/step - loss: 1.2140 - accuracy: 0.4629\n",
      "Test loss: 1.2139564752578735\n",
      "Test accuracy: 0.4628821015357971\n",
      "229/229 [==============================] - 2s 9ms/step\n",
      "[[ 1  4  6  1  8]\n",
      " [ 9  6 10  2 19]\n",
      " [ 2  2  4  0  8]\n",
      " [ 4  3  3  3  2]\n",
      " [19 29 29  8 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.03      0.05      0.04        20\n",
      "  02-Tapered       0.14      0.13      0.13        46\n",
      " 03-Pyriform       0.08      0.25      0.12        16\n",
      "    04-Small       0.21      0.20      0.21        15\n",
      "05-Amorphous       0.56      0.36      0.44       132\n",
      "\n",
      "    accuracy                           0.27       229\n",
      "   macro avg       0.20      0.20      0.19       229\n",
      "weighted avg       0.37      0.27      0.30       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(final_mode, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "6c76c2c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 4s 11ms/step - loss: 1.2140 - accuracy: 0.4629\n",
      "Test loss: 1.2139568328857422\n",
      "Test accuracy: 0.4628821015357971\n",
      "229/229 [==============================] - 3s 11ms/step\n",
      "[[ 4  1  4  1 10]\n",
      " [ 8 10 10  4 14]\n",
      " [ 2  2  2  0 10]\n",
      " [ 2  1  1  0 11]\n",
      " [19 30 35  9 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.11      0.20      0.15        20\n",
      "  02-Tapered       0.23      0.22      0.22        46\n",
      " 03-Pyriform       0.04      0.12      0.06        16\n",
      "    04-Small       0.00      0.00      0.00        15\n",
      "05-Amorphous       0.46      0.30      0.36       132\n",
      "\n",
      "    accuracy                           0.24       229\n",
      "   macro avg       0.17      0.17      0.16       229\n",
      "weighted avg       0.33      0.24      0.27       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(final_mode, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "788246ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 2s 11ms/step - loss: 1.1365 - accuracy: 0.5197\n",
      "Test loss: 1.1365021467208862\n",
      "Test accuracy: 0.5196506381034851\n",
      "229/229 [==============================] - 2s 11ms/step\n",
      "[[ 2  3  1  5  9]\n",
      " [ 4 12  8  5 17]\n",
      " [ 0  2  3  1 10]\n",
      " [ 1  2  2  3  7]\n",
      " [17 24 28  9 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.08      0.10      0.09        20\n",
      "  02-Tapered       0.28      0.26      0.27        46\n",
      " 03-Pyriform       0.07      0.19      0.10        16\n",
      "    04-Small       0.13      0.20      0.16        15\n",
      "05-Amorphous       0.56      0.41      0.47       132\n",
      "\n",
      "    accuracy                           0.32       229\n",
      "   macro avg       0.22      0.23      0.22       229\n",
      "weighted avg       0.40      0.32      0.35       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4b6fcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9f7f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc37635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ef346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "8b47d7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_17',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, None),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'conv2d_34_input'}},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_34',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (4, 4),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_119',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([3]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_35',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (2, 2),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_120',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([3]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_17',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_121',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([3]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Flatten',\n",
       "   'config': {'name': 'flatten_17',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_68',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 576,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_122',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([1]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_69',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1024,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_123',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([1]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_34',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.4,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_70',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 256,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_124',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([1]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_35',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.4,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_71',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 5,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_125',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([1]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_17',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'softmax'}}]}"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn6.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "81a22082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_16',\n",
       " 'layers': [{'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_32',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (4, 4),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_112',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': -1,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_33',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (2, 2),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_113',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': -1,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_16',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_114',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': -1,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Flatten',\n",
       "   'config': {'name': 'flatten_16',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_64',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 576,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_115',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': -1,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_65',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1024,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_116',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': -1,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_32',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.4,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_66',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 256,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_117',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': -1,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_33',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.4,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_67',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 5,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_118',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': -1,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_16',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'softmax'}}]}"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn5.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "64727cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 2s 10ms/step - loss: 1.2140 - accuracy: 0.4629\n",
      "Test loss: 1.2139562368392944\n",
      "Test accuracy: 0.4628821015357971\n",
      "229/229 [==============================] - 2s 9ms/step\n",
      "[[ 4  3  5  0  8]\n",
      " [11 10  6  2 17]\n",
      " [ 2  4  4  1  5]\n",
      " [ 1  7  2  1  4]\n",
      " [17 20 35 10 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   01-Normal       0.11      0.20      0.15        20\n",
      "  02-Tapered       0.23      0.22      0.22        46\n",
      " 03-Pyriform       0.08      0.25      0.12        16\n",
      "    04-Small       0.07      0.07      0.07        15\n",
      "05-Amorphous       0.60      0.38      0.46       132\n",
      "\n",
      "    accuracy                           0.30       229\n",
      "   macro avg       0.22      0.22      0.20       229\n",
      "weighted avg       0.41      0.30      0.34       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluarModelo(final_mode, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7013491",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluarModelo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11278/3061871320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluarModelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluarModelo' is not defined"
     ]
    }
   ],
   "source": [
    "evaluarModelo(vgg16_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "a7ef3057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, None, None, 32)    544       \n",
      "                                                                 \n",
      " batch_normalization_119 (Ba  (None, None, None, 32)   128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, None, None, 64)    8256      \n",
      "                                                                 \n",
      " batch_normalization_120 (Ba  (None, None, None, 64)   256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, None, None, 64)   0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_121 (Ba  (None, None, None, 64)   256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, None)              0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 576)               10654272  \n",
      "                                                                 \n",
      " batch_normalization_122 (Ba  (None, 576)              2304      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1024)              590848    \n",
      "                                                                 \n",
      " batch_normalization_123 (Ba  (None, 1024)             4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_124 (Ba  (None, 256)              1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      " batch_normalization_125 (Ba  (None, 5)                20        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,525,689\n",
      "Trainable params: 11,521,647\n",
      "Non-trainable params: 4,042\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b381da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a46e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(33, 33, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(2, 2), input_shape=input_shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9d164a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4b282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45cee87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b33d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a593e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c580a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5520 - accuracy: 0.2806\n",
      "Epoch 1: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 45s 113ms/step - loss: 1.5520 - accuracy: 0.2806 - val_loss: 1.6297 - val_accuracy: 0.0694 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4033 - accuracy: 0.3836\n",
      "Epoch 2: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 1.4033 - accuracy: 0.3836 - val_loss: 1.2622 - val_accuracy: 0.3179 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3100 - accuracy: 0.4274\n",
      "Epoch 3: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.3100 - accuracy: 0.4274 - val_loss: 1.3267 - val_accuracy: 0.3295 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2482 - accuracy: 0.4594\n",
      "Epoch 4: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.2482 - accuracy: 0.4594 - val_loss: 1.2865 - val_accuracy: 0.3353 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1986 - accuracy: 0.4897\n",
      "Epoch 5: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 1.1986 - accuracy: 0.4897 - val_loss: 1.3456 - val_accuracy: 0.2948 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1623 - accuracy: 0.5097\n",
      "Epoch 6: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.1623 - accuracy: 0.5097 - val_loss: 1.3867 - val_accuracy: 0.2486 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1297 - accuracy: 0.5250\n",
      "Epoch 7: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.1297 - accuracy: 0.5250 - val_loss: 1.2239 - val_accuracy: 0.3179 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0895 - accuracy: 0.5462\n",
      "Epoch 8: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.0895 - accuracy: 0.5462 - val_loss: 1.2154 - val_accuracy: 0.3642 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0759 - accuracy: 0.5512\n",
      "Epoch 9: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 1.0759 - accuracy: 0.5512 - val_loss: 1.1875 - val_accuracy: 0.3699 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0497 - accuracy: 0.5616\n",
      "Epoch 10: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.0497 - accuracy: 0.5616 - val_loss: 1.2086 - val_accuracy: 0.3526 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0380 - accuracy: 0.5687\n",
      "Epoch 11: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.0380 - accuracy: 0.5687 - val_loss: 1.2371 - val_accuracy: 0.3584 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0120 - accuracy: 0.5789\n",
      "Epoch 12: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 1.0120 - accuracy: 0.5789 - val_loss: 1.2388 - val_accuracy: 0.3815 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0099 - accuracy: 0.5794\n",
      "Epoch 13: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 1.0099 - accuracy: 0.5794 - val_loss: 1.1542 - val_accuracy: 0.4277 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9894 - accuracy: 0.5920\n",
      "Epoch 14: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 114ms/step - loss: 0.9894 - accuracy: 0.5920 - val_loss: 1.2301 - val_accuracy: 0.3815 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9894 - accuracy: 0.5916\n",
      "Epoch 15: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.9894 - accuracy: 0.5916 - val_loss: 1.0976 - val_accuracy: 0.4566 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9701 - accuracy: 0.6019\n",
      "Epoch 16: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.9701 - accuracy: 0.6019 - val_loss: 1.2031 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9648 - accuracy: 0.6040\n",
      "Epoch 17: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.9648 - accuracy: 0.6040 - val_loss: 1.2442 - val_accuracy: 0.4046 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9480 - accuracy: 0.6117\n",
      "Epoch 18: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.9480 - accuracy: 0.6117 - val_loss: 1.1445 - val_accuracy: 0.4046 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9511 - accuracy: 0.6088\n",
      "Epoch 19: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.9511 - accuracy: 0.6088 - val_loss: 1.5154 - val_accuracy: 0.3353 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.6144\n",
      "Epoch 20: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.9428 - accuracy: 0.6144 - val_loss: 1.0328 - val_accuracy: 0.5376 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9370 - accuracy: 0.6183\n",
      "Epoch 21: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.9370 - accuracy: 0.6183 - val_loss: 1.2032 - val_accuracy: 0.3757 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9226 - accuracy: 0.6229\n",
      "Epoch 22: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.9226 - accuracy: 0.6229 - val_loss: 1.1642 - val_accuracy: 0.4162 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9186 - accuracy: 0.6237\n",
      "Epoch 23: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.9186 - accuracy: 0.6237 - val_loss: 1.3148 - val_accuracy: 0.4220 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.6300\n",
      "Epoch 24: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.9140 - accuracy: 0.6300 - val_loss: 1.3219 - val_accuracy: 0.3988 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.6285\n",
      "Epoch 25: val_accuracy did not improve from 0.64162\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.9092 - accuracy: 0.6285 - val_loss: 1.2360 - val_accuracy: 0.4104 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8589 - accuracy: 0.6504\n",
      "Epoch 26: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.8589 - accuracy: 0.6504 - val_loss: 1.0638 - val_accuracy: 0.5318 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8506 - accuracy: 0.6565\n",
      "Epoch 27: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.8506 - accuracy: 0.6565 - val_loss: 1.1353 - val_accuracy: 0.4624 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8410 - accuracy: 0.6565\n",
      "Epoch 28: val_accuracy did not improve from 0.64162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 44s 112ms/step - loss: 0.8410 - accuracy: 0.6565 - val_loss: 1.0404 - val_accuracy: 0.5145 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.6614\n",
      "Epoch 29: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.8302 - accuracy: 0.6614 - val_loss: 1.3974 - val_accuracy: 0.3988 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8241 - accuracy: 0.6646\n",
      "Epoch 30: val_accuracy did not improve from 0.64162\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.8241 - accuracy: 0.6646 - val_loss: 1.2121 - val_accuracy: 0.4798 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.6763\n",
      "Epoch 31: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.8012 - accuracy: 0.6763 - val_loss: 1.1067 - val_accuracy: 0.4798 - lr: 2.5000e-04\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7906 - accuracy: 0.6799\n",
      "Epoch 32: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7906 - accuracy: 0.6799 - val_loss: 0.9499 - val_accuracy: 0.6012 - lr: 2.5000e-04\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7900 - accuracy: 0.6797\n",
      "Epoch 33: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7900 - accuracy: 0.6797 - val_loss: 1.0651 - val_accuracy: 0.5434 - lr: 2.5000e-04\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7847 - accuracy: 0.6874\n",
      "Epoch 34: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7847 - accuracy: 0.6874 - val_loss: 1.0586 - val_accuracy: 0.5434 - lr: 2.5000e-04\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7793 - accuracy: 0.6847\n",
      "Epoch 35: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7793 - accuracy: 0.6847 - val_loss: 1.2210 - val_accuracy: 0.4566 - lr: 2.5000e-04\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7824 - accuracy: 0.6866\n",
      "Epoch 36: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7824 - accuracy: 0.6866 - val_loss: 1.0920 - val_accuracy: 0.5376 - lr: 2.5000e-04\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7775 - accuracy: 0.6852\n",
      "Epoch 37: val_accuracy did not improve from 0.64162\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7775 - accuracy: 0.6852 - val_loss: 1.0175 - val_accuracy: 0.5491 - lr: 2.5000e-04\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.6987\n",
      "Epoch 38: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7608 - accuracy: 0.6987 - val_loss: 1.0357 - val_accuracy: 0.5549 - lr: 1.2500e-04\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7603 - accuracy: 0.6946\n",
      "Epoch 39: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7603 - accuracy: 0.6946 - val_loss: 1.0680 - val_accuracy: 0.5202 - lr: 1.2500e-04\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.6972\n",
      "Epoch 40: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7608 - accuracy: 0.6972 - val_loss: 1.1348 - val_accuracy: 0.5202 - lr: 1.2500e-04\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7579 - accuracy: 0.6982\n",
      "Epoch 41: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7579 - accuracy: 0.6982 - val_loss: 1.0942 - val_accuracy: 0.5260 - lr: 1.2500e-04\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7511 - accuracy: 0.6993\n",
      "Epoch 42: val_accuracy did not improve from 0.64162\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7511 - accuracy: 0.6993 - val_loss: 1.0173 - val_accuracy: 0.5549 - lr: 1.2500e-04\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7467 - accuracy: 0.7010\n",
      "Epoch 43: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7467 - accuracy: 0.7010 - val_loss: 0.9832 - val_accuracy: 0.5954 - lr: 6.2500e-05\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7456 - accuracy: 0.7016\n",
      "Epoch 44: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.7456 - accuracy: 0.7016 - val_loss: 1.0153 - val_accuracy: 0.5723 - lr: 6.2500e-05\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7059\n",
      "Epoch 45: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7395 - accuracy: 0.7059 - val_loss: 1.0679 - val_accuracy: 0.5376 - lr: 6.2500e-05\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.7078\n",
      "Epoch 46: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7375 - accuracy: 0.7078 - val_loss: 1.0596 - val_accuracy: 0.5491 - lr: 6.2500e-05\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.7046\n",
      "Epoch 47: val_accuracy did not improve from 0.64162\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7392 - accuracy: 0.7046 - val_loss: 1.0252 - val_accuracy: 0.5723 - lr: 6.2500e-05\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7384 - accuracy: 0.7047\n",
      "Epoch 48: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 45s 114ms/step - loss: 0.7384 - accuracy: 0.7047 - val_loss: 1.0335 - val_accuracy: 0.5723 - lr: 3.1250e-05\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.7023\n",
      "Epoch 49: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.7392 - accuracy: 0.7023 - val_loss: 1.0608 - val_accuracy: 0.5665 - lr: 3.1250e-05\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7318 - accuracy: 0.7069\n",
      "Epoch 50: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 112ms/step - loss: 0.7318 - accuracy: 0.7069 - val_loss: 1.0542 - val_accuracy: 0.5665 - lr: 3.1250e-05\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7325 - accuracy: 0.7056\n",
      "Epoch 51: val_accuracy did not improve from 0.64162\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.7325 - accuracy: 0.7056 - val_loss: 1.0212 - val_accuracy: 0.5549 - lr: 3.1250e-05\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7327 - accuracy: 0.7072\n",
      "Epoch 52: val_accuracy did not improve from 0.64162\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "391/391 [==============================] - 44s 113ms/step - loss: 0.7327 - accuracy: 0.7072 - val_loss: 1.0394 - val_accuracy: 0.5376 - lr: 3.1250e-05\n",
      "Epoch 52: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(cnn_training,\n",
    "        epochs=200, \n",
    "        validation_data=cnn_val,\n",
    "        verbose = 1, \n",
    "        callbacks = [mc, reduce_lr, es,cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede83a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab265e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c988563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f1c0db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images : 5000\n",
      "Images : 5000\n",
      "Images : 5000\n",
      "Images : 5000\n",
      "Images : 5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b53ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdded04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "093fab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file count: 5000\n"
     ]
    }
   ],
   "source": [
    "path = '/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/final_data'\n",
    "fill( path+'/train/01-Normal' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c59b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c0535f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539d628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377be424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51dc665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d861538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2041c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363c96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5489c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be745399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e9b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e9bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "57f70442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from scikit-image) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from scikit-image) (21.3)\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.22.2-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx>=2.2\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from scikit-image) (1.7.3)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "Installing collected packages: tifffile, PyWavelets, networkx, imageio, scikit-image\n",
      "Successfully installed PyWavelets-1.3.0 imageio-2.22.2 networkx-2.6.3 scikit-image-0.19.3 tifffile-2021.11.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "29d6d3a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'p1-pl2-sample01/Sperm_01\\t5\\t5\\t5\\t5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26418/3760808000.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data-set/PA-expert-annotations.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'p1-pl2-sample01/Sperm_01\\t5\\t5\\t5\\t5'"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('Data-set/PA-expert-annotations.txt', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8720a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_labels = list(cnn_test.class_indices.keys())   \n",
    "\n",
    "#print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "#eport = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "#print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4488cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predicted probality\n",
    "#prediction = cnn_model.predict(cnn_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "#predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "#true_classes = cnn_test.classes\n",
    "\n",
    "#train_labels, val_labels = cnn_training.classes, cnn_val.classes\n",
    "#pred_train, pred_val = np.argmax(cnn_model.predict(cnn_training), axis = 1), np.argmax(cnn_model.predict(cnn_val), axis = 1)\n",
    "\n",
    "#imprimirMetricas(train_labels, pred_train , val_labels, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a2b6829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 20s 50ms/step\n",
      "3/3 [==============================] - 0s 28ms/step\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.20      0.20      5000\n",
      "           1       0.20      0.21      0.20      5000\n",
      "           2       0.19      0.19      0.19      5000\n",
      "           3       0.20      0.23      0.22      5000\n",
      "           4       0.20      0.16      0.18      5000\n",
      "\n",
      "    accuracy                           0.20     25000\n",
      "   macro avg       0.20      0.20      0.20     25000\n",
      "weighted avg       0.20      0.20      0.20     25000\n",
      "\n",
      "[[1006 1091  986 1088  829]\n",
      " [ 967 1058 1012 1137  826]\n",
      " [ 945 1097  946 1143  869]\n",
      " [ 956 1073 1003 1171  797]\n",
      " [ 961 1072  957 1193  817]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.07      0.06        15\n",
      "           1       0.20      0.37      0.26        35\n",
      "           2       0.11      0.17      0.13        12\n",
      "           3       0.04      0.09      0.06        11\n",
      "           4       0.55      0.27      0.36       100\n",
      "\n",
      "    accuracy                           0.25       173\n",
      "   macro avg       0.19      0.19      0.17       173\n",
      "weighted avg       0.37      0.25      0.28       173\n",
      "\n",
      "[[ 1  4  1  1  8]\n",
      " [ 5 13  2  6  9]\n",
      " [ 3  5  2  0  2]\n",
      " [ 2  5  0  1  3]\n",
      " [ 6 39 13 15 27]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1d94e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f89f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = cnn_model.predict(cnn_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = cnn_test.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = cnn_test.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "df_predictions = pd.DataFrame({'Filename': filenames, 'Label': true_classes, 'CNN Model': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f947ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred =  pd.DataFrame(prediction, columns = ['Class 0', 'Class 1', 'Class 2', 'Class 3','Class 4'], index = filenames)\n",
    "path = '/home/mcoronado/Escritorio/'\n",
    "cnn_pred.to_csv(path+'/Models/Cnn_pred_prob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0be62b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 1s 6ms/step - loss: 1.0649 - accuracy: 0.5333\n",
      "Test loss: 1.0648752450942993\n",
      "Test accuracy: 0.5333333611488342\n",
      "\n",
      "Time: 31.072421113616702 min\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(cnn_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print(\"\\nTime:\",sum(cb.logs)/60,\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2cde9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 20s 52ms/step - loss: 0.8805 - accuracy: 0.6546\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9635 - accuracy: 0.5723\n",
      "Train: 0.655, Val: 0.572\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, train_acc = cnn_model.evaluate(cnn_training, verbose=1)\n",
    "_, val_acc = cnn_model.evaluate(cnn_val, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f9ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 10:53:28.718690: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 42614784 exceeds 10% of free system memory.\n",
      "2022-10-28 10:53:28.737278: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 42614784 exceeds 10% of free system memory.\n",
      "2022-10-28 10:53:28.744596: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 42614784 exceeds 10% of free system memory.\n",
      "2022-10-28 10:53:29.174660: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18939904 exceeds 10% of free system memory.\n",
      "2022-10-28 10:53:29.182460: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18939904 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4890 - accuracy: 0.3352\n",
      "Epoch 1: val_accuracy improved from -inf to 0.08092, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 189s 477ms/step - loss: 1.4890 - accuracy: 0.3352 - val_loss: 2.1797 - val_accuracy: 0.0809 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2610 - accuracy: 0.4648\n",
      "Epoch 2: val_accuracy improved from 0.08092 to 0.46243, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 72s 184ms/step - loss: 1.2610 - accuracy: 0.4648 - val_loss: 1.1775 - val_accuracy: 0.4624 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1295 - accuracy: 0.5344\n",
      "Epoch 3: val_accuracy improved from 0.46243 to 0.52023, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 72s 185ms/step - loss: 1.1295 - accuracy: 0.5344 - val_loss: 1.0602 - val_accuracy: 0.5202 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0309 - accuracy: 0.5859\n",
      "Epoch 4: val_accuracy did not improve from 0.52023\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 1.0309 - accuracy: 0.5859 - val_loss: 1.2265 - val_accuracy: 0.4335 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9407 - accuracy: 0.6302\n",
      "Epoch 5: val_accuracy improved from 0.52023 to 0.57225, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 72s 184ms/step - loss: 0.9407 - accuracy: 0.6302 - val_loss: 0.9635 - val_accuracy: 0.5723 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8815 - accuracy: 0.6535\n",
      "Epoch 6: val_accuracy did not improve from 0.57225\n",
      "391/391 [==============================] - 69s 175ms/step - loss: 0.8815 - accuracy: 0.6535 - val_loss: 0.9879 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8108 - accuracy: 0.6848\n",
      "Epoch 7: val_accuracy did not improve from 0.57225\n",
      "391/391 [==============================] - 68s 175ms/step - loss: 0.8108 - accuracy: 0.6848 - val_loss: 1.1160 - val_accuracy: 0.5202 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.7107\n",
      "Epoch 8: val_accuracy did not improve from 0.57225\n",
      "391/391 [==============================] - 69s 175ms/step - loss: 0.7533 - accuracy: 0.7107 - val_loss: 0.9659 - val_accuracy: 0.5607 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.7280\n",
      "Epoch 9: val_accuracy did not improve from 0.57225\n",
      "391/391 [==============================] - 68s 175ms/step - loss: 0.7105 - accuracy: 0.7280 - val_loss: 1.1353 - val_accuracy: 0.5318 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.7444\n",
      "Epoch 10: val_accuracy improved from 0.57225 to 0.62428, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.6717 - accuracy: 0.7444 - val_loss: 1.0549 - val_accuracy: 0.6243 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5996 - accuracy: 0.7764\n",
      "Epoch 11: val_accuracy did not improve from 0.62428\n",
      "391/391 [==============================] - 69s 175ms/step - loss: 0.5996 - accuracy: 0.7764 - val_loss: 1.0054 - val_accuracy: 0.5954 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7904\n",
      "Epoch 12: val_accuracy did not improve from 0.62428\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.5675 - accuracy: 0.7904 - val_loss: 1.2098 - val_accuracy: 0.5376 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.8082\n",
      "Epoch 13: val_accuracy did not improve from 0.62428\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.5300 - accuracy: 0.8082 - val_loss: 1.0481 - val_accuracy: 0.6012 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8174\n",
      "Epoch 14: val_accuracy did not improve from 0.62428\n",
      "391/391 [==============================] - 69s 175ms/step - loss: 0.5080 - accuracy: 0.8174 - val_loss: 1.2045 - val_accuracy: 0.5896 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.8316\n",
      "Epoch 15: val_accuracy did not improve from 0.62428\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.4710 - accuracy: 0.8316 - val_loss: 1.2536 - val_accuracy: 0.5780 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8467\n",
      "Epoch 16: val_accuracy did not improve from 0.62428\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.4315 - accuracy: 0.8467 - val_loss: 1.1887 - val_accuracy: 0.6012 - lr: 2.5000e-04\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.8548\n",
      "Epoch 17: val_accuracy did not improve from 0.62428\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.4134 - accuracy: 0.8548 - val_loss: 1.2033 - val_accuracy: 0.6127 - lr: 2.5000e-04\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8610\n",
      "Epoch 18: val_accuracy improved from 0.62428 to 0.63006, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4011 - accuracy: 0.8610 - val_loss: 1.1978 - val_accuracy: 0.6301 - lr: 2.5000e-04\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8654\n",
      "Epoch 19: val_accuracy did not improve from 0.63006\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.3806 - accuracy: 0.8654 - val_loss: 1.1939 - val_accuracy: 0.6069 - lr: 2.5000e-04\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8697\n",
      "Epoch 20: val_accuracy did not improve from 0.63006\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.3724 - accuracy: 0.8697 - val_loss: 1.1621 - val_accuracy: 0.5838 - lr: 2.5000e-04\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8821\n",
      "Epoch 21: val_accuracy did not improve from 0.63006\n",
      "391/391 [==============================] - 70s 178ms/step - loss: 0.3401 - accuracy: 0.8821 - val_loss: 1.1782 - val_accuracy: 0.6127 - lr: 1.2500e-04\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.8852\n",
      "Epoch 22: val_accuracy improved from 0.63006 to 0.63584, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 73s 185ms/step - loss: 0.3397 - accuracy: 0.8852 - val_loss: 1.1920 - val_accuracy: 0.6358 - lr: 1.2500e-04\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8892\n",
      "Epoch 23: val_accuracy did not improve from 0.63584\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.3297 - accuracy: 0.8892 - val_loss: 1.2331 - val_accuracy: 0.6127 - lr: 1.2500e-04\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3200 - accuracy: 0.8899\n",
      "Epoch 24: val_accuracy did not improve from 0.63584\n",
      "391/391 [==============================] - 69s 176ms/step - loss: 0.3200 - accuracy: 0.8899 - val_loss: 1.1560 - val_accuracy: 0.6243 - lr: 1.2500e-04\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3094 - accuracy: 0.8944\n",
      "Epoch 25: val_accuracy improved from 0.63584 to 0.64162, saving model to /home/mcoronado/Escritorio/Models_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/mcoronado/Escritorio/Models_A/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.3094 - accuracy: 0.8944 - val_loss: 1.1912 - val_accuracy: 0.6416 - lr: 1.2500e-04\n",
      "Epoch 25: early stopping\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
