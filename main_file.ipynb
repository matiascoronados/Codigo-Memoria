{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d54ad9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "220b126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "LABBELS_NAMES = ['01-Normal', '02-Tapered', '03-Pyriform', '04-Small', '05-Amorphous']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8d2b3",
   "metadata": {},
   "source": [
    "## 1. CARGAR ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d52e57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un archivo en la direccion ingresada, esta se elimina si ya existe.\n",
    "def create_folder( folder_name, dest_path ):\n",
    "    try:\n",
    "        folder_path = dest_path+'/'+folder_name\n",
    "        if os.path.exists(folder_path):\n",
    "            shutil.rmtree(folder_path)   \n",
    "        os.mkdir(folder_path)\n",
    "        return True\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f0c1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el data-set a partir del .txt, y las imagenes parciales de entrada.\n",
    "def create_dataset(path_expertAnotations,path_partialImages, dest_path, dataset_name):\n",
    "    try:\n",
    "        file = open(path_expertAnotations, 'r')\n",
    "        create_folder(dataset_name, dest_path)\n",
    "        for labbel_name in LABBELS_NAMES:\n",
    "            create_folder( labbel_name ,dest_path+'/'+dataset_name)\n",
    "        for x in file:\n",
    "            # Se obtiene el nombre y clase desde el archivo txt\n",
    "            aux1 = x.split('\t')\n",
    "            aux2 = aux1[0].replace('\\n','').split('-')\n",
    "            aux3 = aux2[2].split('/')\n",
    "            clase = int(aux1[4].replace('\\n',''))\n",
    "            p = aux2[0]\n",
    "            pl = aux2[1]\n",
    "            n_sample = int(re.split('(\\d+)',aux3[0])[1])\n",
    "            n_sperm = int(re.split('(\\d+)',aux3[1])[1])\n",
    "            # Se conforma el directorio de la imagen a partir de la informacion anterior.\n",
    "            file = path_partialImages+'ch00_'+p+'-'+pl+'-sample'+str(n_sample)+'-sperm'+str(n_sperm)+'.tif'\n",
    "            # Se conforma el directorio donde se va a copiar la imagen\n",
    "            aux = dest_path+'/'+dataset_name+'/'\n",
    "            if (clase == 0):\n",
    "                aux=aux+'01-Normal'\n",
    "            elif (clase == 1):\n",
    "                aux=aux+'02-Tapered'\n",
    "            elif (clase == 2):\n",
    "                aux=aux+'03-Pyriform'\n",
    "            elif (clase == 3):\n",
    "                aux=aux+'04-Small'\n",
    "            else:\n",
    "                aux=aux+'05-Amorphous'\n",
    "            # Se copia la imagen\n",
    "            shutil.copy(file,aux)  \n",
    "        return True\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe93ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_element(origin_path, dest_path):\n",
    "    try:\n",
    "        shutil.copy( origin_path, dest_path)\n",
    "        return True\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23244030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elige aleatoriamente un elemento de la lista, y luego lo elimina de esta.\n",
    "def choose_random_element(elements_list):\n",
    "    element = random.choice(elements_list)\n",
    "    elements_list.remove(element)\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0e46b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean los conjuntos train, valid y test a partir de las imagenes.\n",
    "def create_train_valid_test( origin_path, dest_path, dataset_name,porcentages):\n",
    "    create_folder(dataset_name, dest_path)\n",
    "    dataset_path = dest_path+'/'+dataset_name\n",
    "    create_folder('train', dataset_path)\n",
    "    create_folder('test', dataset_path)\n",
    "    create_folder('valid', dataset_path)\n",
    "    \n",
    "    for labbel_name in LABBELS_NAMES:\n",
    "        create_folder( labbel_name, dataset_path+'/train' )\n",
    "        create_folder( labbel_name, dataset_path+'/test' )\n",
    "        create_folder( labbel_name, dataset_path+'/valid' )\n",
    "        try:\n",
    "            all_class_images = os.listdir(origin_path+'/'+labbel_name)\n",
    "            count_class_images = len(all_class_images)\n",
    "            origin_class_path = origin_path+'/'+labbel_name\n",
    "            # Archivos test\n",
    "            aux_count = 0\n",
    "            while int(count_class_images*porcentages[0]) > aux_count:\n",
    "                image_name = choose_random_element(all_class_images)\n",
    "                copy_element( origin_class_path+'/'+image_name, dataset_path+'/test/'+labbel_name+'/'+image_name)\n",
    "                aux_count = aux_count+1\n",
    "            aux_count = 0\n",
    "            # Archivos valid\n",
    "            while int(count_class_images*porcentages[1]) > aux_count:\n",
    "                image_name = choose_random_element(all_class_images)\n",
    "                copy_element( origin_class_path+'/'+image_name, dataset_path+'/valid/'+labbel_name+'/'+image_name)\n",
    "                aux_count = aux_count+1\n",
    "            aux_count = 0\n",
    "             # Archivos train\n",
    "            while len(all_class_images) != 0:\n",
    "                image_name = choose_random_element(all_class_images)\n",
    "                copy_element( origin_class_path+'/'+image_name, dataset_path+'/train/'+labbel_name+'/'+image_name)\n",
    "        except OSError as err:\n",
    "            print(\"OS error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ef84737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, batch_size, target_size):\n",
    "    \n",
    "    dataGen_train = ImageDataGenerator(rescale = 1./255) \n",
    "    dataGen_valid = ImageDataGenerator(rescale = 1./255)\n",
    "    dataGen_test = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    #test different color maps -  class modes and cross validation types\n",
    "    train = dataGen_train.flow_from_directory(data_path+'/train',\n",
    "                                                     target_size = target_size,\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     shuffle = True,\n",
    "                                                     class_mode=\"categorical\")\n",
    "\n",
    "    valid = dataGen_valid.flow_from_directory(data_path+'/valid',\n",
    "                                                target_size = target_size,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True,\n",
    "                                                class_mode=\"categorical\")\n",
    "\n",
    "    test = dataGen_test.flow_from_directory(data_path+'/test',\n",
    "                                                target_size = target_size,\n",
    "                                                batch_size = 1,\n",
    "                                                shuffle = True,\n",
    "                                                class_mode=\"categorical\")\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "162 \n",
    "28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "752c8758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 5 classes.\n",
      "Found 155 images belonging to 5 classes.\n",
      "Found 337 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "main_path = '/home/mcoronado/Escritorio/Codigo-Memoria/'\n",
    "raw_dataset_name = 'raw_data'\n",
    "dataset_name = 'data'\n",
    "\n",
    "test_porcentage = 0.3\n",
    "valid_porcentage = 0.7*0.2\n",
    "train_porcentage = 0.7*0.8\n",
    "\n",
    "image_dimention = (35,35)\n",
    "batch_size = 64\n",
    "\n",
    "create_dataset(path_expertAnotations = main_path+'Data-set/PA-expert-annotations.txt', \n",
    "              path_partialImages = main_path+'Data-set/Partial-Agreement-Images/',\n",
    "              dest_path = main_path+'Data-set',\n",
    "              dataset_name = raw_dataset_name)\n",
    "\n",
    "create_train_valid_test(origin_path=main_path+'Data-set/'+raw_dataset_name,\n",
    "                        dest_path=main_path+'Data-set/',\n",
    "                        dataset_name = dataset_name,\n",
    "                        porcentages = [test_porcentage,valid_porcentage,train_porcentage])\n",
    "\n",
    "dataset_path = main_path+'Data-set/'+dataset_name\n",
    "\n",
    "train, valid, test = load_data( dataset_path, batch_size, image_dimention)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e45c1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ad6443a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14562/793253936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"path/to/image.tiff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "import rasterio\n",
    "image = rasterio.open(f\"path/to/image.tiff\")\n",
    "image = image.read()\n",
    "image = ToTensor()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7045b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from torchvision) (4.4.0)\n",
      "Collecting torch==1.13.0\n",
      "  Downloading torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m416.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m711.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (63.4.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages (from requests->torchvision) (1.26.12)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No queda espacio en el dispositivo\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbdc10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
