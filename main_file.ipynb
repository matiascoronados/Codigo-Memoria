{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54ad9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pdb\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220b126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "LABBELS_NAMES = ['01-Normal', '02-Tapered', '03-Pyriform', '04-Small', '05-Amorphous']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8d2b3",
   "metadata": {},
   "source": [
    "## 1. FUNCIONES PARA CARGAR Y DIVIDIR ARCHIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52e57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un archivo en la direccion ingresada, esta se elimina si ya existe.\n",
    "def create_folder( folder_name, dest_path ):\n",
    "    try:\n",
    "        folder_path = dest_path+'/'+folder_name\n",
    "        if os.path.exists(folder_path):\n",
    "            shutil.rmtree(folder_path)   \n",
    "        os.mkdir(folder_path)\n",
    "        return True\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae257e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un archivo en la direccion ingresada\n",
    "def create_folder_wremoving( folder_name, dest_path ):\n",
    "    try:\n",
    "        folder_path = dest_path+folder_name\n",
    "        if not(os.path.exists(folder_path)):\n",
    "            os.mkdir(folder_path)\n",
    "        return True\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0c1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el data-set a partir de la informacion presente en expertAnotations.txt, y las partialImages de entrada.\n",
    "def create_dataset(path_expertAnotations,path_partialImages, dest_path, dataset_name):\n",
    "    try:\n",
    "        file = open(path_expertAnotations, 'r')\n",
    "        create_folder(dataset_name, dest_path)\n",
    "        for labbel_name in LABBELS_NAMES:\n",
    "            create_folder( labbel_name ,dest_path+'/'+dataset_name)\n",
    "        for x in file:\n",
    "            # Se obtiene el nombre y clase desde el archivo txt\n",
    "            aux1 = x.split('\t')\n",
    "            aux2 = aux1[0].replace('\\n','').split('-')\n",
    "            aux3 = aux2[2].split('/')\n",
    "            clase = int(aux1[4].replace('\\n',''))\n",
    "            p = aux2[0]\n",
    "            pl = aux2[1]\n",
    "            n_sample = int(re.split('(\\d+)',aux3[0])[1])\n",
    "            n_sperm = int(re.split('(\\d+)',aux3[1])[1])\n",
    "            # Se conforma el directorio de la imagen a partir de la informacion anterior.\n",
    "            file = path_partialImages+'ch00_'+p+'-'+pl+'-sample'+str(n_sample)+'-sperm'+str(n_sperm)+'.tif'\n",
    "            # Se conforma el directorio donde se va a copiar la imagen\n",
    "            aux = dest_path+'/'+dataset_name+'/'\n",
    "            if (clase == 0):\n",
    "                aux=aux+'01-Normal'\n",
    "            elif (clase == 1):\n",
    "                aux=aux+'02-Tapered'\n",
    "            elif (clase == 2):\n",
    "                aux=aux+'03-Pyriform'\n",
    "            elif (clase == 3):\n",
    "                aux=aux+'04-Small'\n",
    "            else:\n",
    "                aux=aux+'05-Amorphous'\n",
    "            # Se copia la imagen\n",
    "            shutil.copy(file,aux)  \n",
    "        return True\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe93ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_element(origin_path, dest_path):\n",
    "    try:\n",
    "        shutil.copy( origin_path, dest_path)\n",
    "        return True\n",
    "    except OSError as err:\n",
    "        print(\"OS error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23244030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elige aleatoriamente un elemento de la lista, y luego lo elimina de esta.\n",
    "def choose_random_element(elements_list):\n",
    "    element = random.choice(elements_list)\n",
    "    elements_list.remove(element)\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e46b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean los conjuntos train, valid y test a partir de las imagenes.\n",
    "def create_train_valid_test( origin_path, dest_path, dataset_name,porcentages):\n",
    "    create_folder(dataset_name, dest_path)\n",
    "    dataset_path = dest_path+'/'+dataset_name\n",
    "    create_folder('train', dataset_path)\n",
    "    create_folder('test', dataset_path)\n",
    "    create_folder('valid', dataset_path)\n",
    "    \n",
    "    for labbel_name in LABBELS_NAMES:\n",
    "        create_folder( labbel_name, dataset_path+'/train' )\n",
    "        create_folder( labbel_name, dataset_path+'/test' )\n",
    "        create_folder( labbel_name, dataset_path+'/valid' )\n",
    "        try:\n",
    "            all_class_images = os.listdir(origin_path+'/'+labbel_name)\n",
    "            count_class_images = len(all_class_images)\n",
    "            origin_class_path = origin_path+'/'+labbel_name\n",
    "            # Archivos test\n",
    "            aux_count = 0\n",
    "            while int(count_class_images*porcentages[0]) > aux_count:\n",
    "                image_name = choose_random_element(all_class_images)\n",
    "                copy_element( origin_class_path+'/'+image_name, dataset_path+'/test/'+labbel_name+'/'+image_name)\n",
    "                aux_count = aux_count+1\n",
    "            aux_count = 0\n",
    "            # Archivos valid\n",
    "            while int(count_class_images*porcentages[1]) > aux_count:\n",
    "                image_name = choose_random_element(all_class_images)\n",
    "                copy_element( origin_class_path+'/'+image_name, dataset_path+'/valid/'+labbel_name+'/'+image_name)\n",
    "                aux_count = aux_count+1\n",
    "            aux_count = 0\n",
    "             # Archivos train\n",
    "            while len(all_class_images) != 0:\n",
    "                image_name = choose_random_element(all_class_images)\n",
    "                copy_element( origin_class_path+'/'+image_name, dataset_path+'/train/'+labbel_name+'/'+image_name)\n",
    "        except OSError as err:\n",
    "            print(\"OS error:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef84737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_data_tf_format(data_path, batch_size, target_size):\n",
    "    \n",
    "    dataGen_train = ImageDataGenerator(rescale = 1./255) \n",
    "    dataGen_valid = ImageDataGenerator(rescale = 1./255)\n",
    "    dataGen_test = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    #test different color maps -  class modes and cross validation types\n",
    "    train = dataGen_train.flow_from_directory(data_path+'/train',\n",
    "                                                     target_size = target_size,\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     shuffle = True,\n",
    "                                                     class_mode=\"categorical\")\n",
    "\n",
    "    valid = dataGen_valid.flow_from_directory(data_path+'/valid',\n",
    "                                                target_size = target_size,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True,\n",
    "                                                class_mode=\"categorical\")\n",
    "\n",
    "    test = dataGen_test.flow_from_directory(data_path+'/test',\n",
    "                                                target_size = target_size,\n",
    "                                                batch_size = 1,\n",
    "                                                shuffle = True,\n",
    "                                                class_mode=\"categorical\")\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_pytorch_format( dataset_path, batch_size, image_dimention ):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_dimention[0]),\n",
    "        transforms.ToTensor()])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(root=dataset_path+'/train', \n",
    "                                         transform=transform)\n",
    "    valid_dataset = datasets.ImageFolder(root=dataset_path+'/valid',\n",
    "                                         transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=dataset_path+'/test',\n",
    "                                        transform=transform)    \n",
    "\n",
    "    train_loader = DataLoader( train_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=1, \n",
    "                              pin_memory=True)\n",
    "    valid_loader = DataLoader( valid_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,\n",
    "                              num_workers=1, \n",
    "                              pin_memory=True)\n",
    "    test_loader = DataLoader( test_dataset, \n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=True,\n",
    "                             num_workers=1, \n",
    "                             pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495dd7fd",
   "metadata": {},
   "source": [
    "# 2.FUNCIONES DE DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b91e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init(m):\n",
    "    if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "        m.weight.data=torch.randn(m.weight.size())*.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b164591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, criterion , device):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    count_minibatchs = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_acc += (preds == labels).sum().item()\n",
    "\n",
    "        count_minibatchs = i+1\n",
    "        \n",
    "    epoch_loss = running_loss / count_minibatchs\n",
    "    epoch_acc = 100. * (running_acc / len(trainloader.dataset))\n",
    "    print(f\"loss: {epoch_loss:.3f}, accuracy: {epoch_acc:.3f}\")\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15687e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, validloader, criterion, device):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    count_minibatchs = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # forward\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_acc += (preds == labels).sum().item()\n",
    "\n",
    "            count_minibatchs = i+1\n",
    "    epoch_loss = running_loss / count_minibatchs\n",
    "    epoch_acc = 100. * (running_acc / len(validloader.dataset))\n",
    "    print(f\"val_loss: {epoch_loss:.3f}, val_accuracy: {epoch_acc:.3f}\")\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a959f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader, device):\n",
    "    y_pred, y_original = [], []\n",
    "    for i, data in enumerate(testloader,0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels\n",
    "\n",
    "        # get original labbels\n",
    "        y_original.extend(labels.numpy())\n",
    "\n",
    "        # forward\n",
    "        outputs=net(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        preds = preds.cpu()\n",
    "        y_pred.extend(preds.numpy())\n",
    "\n",
    "    return y_pred,y_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f88ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model( net, model_state, device):\n",
    "    net.load_state_dict( model_state )\n",
    "    net.to(device)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2cb2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_acc_plot(train_acc, valid_acc, model_save_path):\n",
    "    try:\n",
    "        plt.figure()\n",
    "        plt.plot(train_acc, color='red', label='train acc')\n",
    "        plt.plot(valid_acc, color='blue', label='valid acc')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.savefig(model_save_path+'/accuracy.png')\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a7f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss_plot(train_loss, valid_loss, model_save_path):\n",
    "    try:\n",
    "        plt.figure()\n",
    "        plt.plot(train_loss, color='red', label='train loss')\n",
    "        plt.plot(valid_loss, color='blue', label='valid loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(model_save_path+'/loss.png')    \n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e078ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion_matrix(y_true, y_pred, model_save_path):\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    file= open(model_save_path+\"/general_scores.txt\",\"w+\")\n",
    "    file.write(f\"Precision Score: {precision:.3f}\\n\")\n",
    "    file.write(f\"Recall Score: {recall:.3f}\\n\")\n",
    "    file.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    df_cm = pd.DataFrame(cf_matrix, index = [class_name for class_name in LABBELS_NAMES], columns = [class_name for class_name in LABBELS_NAMES])\n",
    "    plt.figure()\n",
    "    sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='d')\n",
    "    plt.savefig(model_save_path+'/confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b03db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_net( net, epochs, trainloader, validloader, testloader, optimizer, criterion, model_save_path):\n",
    "    aux = net\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    train_loss, valid_loss ,train_acc, valid_acc = [],[],[],[]\n",
    "    \n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    net = net.to(device)\n",
    "    best_vloss = float('inf')\n",
    "    best_model_state= []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        train_epoch_loss, train_epoch_acc = train(net, trainloader, optimizer, criterion,device)\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        train_acc.append(train_epoch_acc)\n",
    "\n",
    "        valid_epoch_loss, valid_epoch_acc = validate(net, validloader, criterion,device)        \n",
    "        valid_loss.append(valid_epoch_loss)\n",
    "        valid_acc.append(valid_epoch_acc)\n",
    "\n",
    "        if valid_epoch_loss < best_vloss:\n",
    "            best_vloss = valid_epoch_loss\n",
    "            best_model_state = net.state_dict()\n",
    "        print(\"\\n\\n\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "    best_net = load_model( aux, best_model_state, device)\n",
    "    time.sleep(1)\n",
    "    y_pred,y_true = test(best_net, testloader, device)\n",
    "    \n",
    "    save_acc_plot(train_acc, valid_acc, model_save_path)\n",
    "    save_loss_plot(train_loss, valid_loss, model_save_path)\n",
    "    save_confusion_matrix(y_true, y_pred, model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533782b",
   "metadata": {},
   "source": [
    "# 3. FUNCIONES PARA ELIMINAR BORDES NEGROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8368315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_white_pixels( imag, pixel_list ):\n",
    "    for element in pixel_list:\n",
    "        i = element[0]\n",
    "        j = element[1]\n",
    "        imag[ i, j ] = 255\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5a08ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frecuent_value( arr ):\n",
    "    count = 0\n",
    "    aux = arr[0]\n",
    "    for i in range(len(arr)-1):\n",
    "        frec = arr.count(arr[i])\n",
    "        if(frec > count):\n",
    "            count = frec\n",
    "            aux = arr[i]\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505019cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_elements(arr, element):\n",
    "    return [x for x in arr if x != element]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a966d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_values( all_pixels ):\n",
    "    all_pixels = remove_elements(all_pixels, 0)\n",
    "\n",
    "    new_value1 = get_most_frecuent_value(all_pixels)\n",
    "    all_pixels = remove_elements(all_pixels, new_value1)\n",
    "    aux1 = new_value1\n",
    "    \n",
    "    return [aux1-1,aux1,aux1+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c5d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_dots( imag, i, j ):\n",
    "    rows, cols = imag.shape\n",
    "    list_elements = []\n",
    "    list_elements.append([i,j])\n",
    "    list_blackdots = []\n",
    "    for element in list_elements:\n",
    "        i = element[0]\n",
    "        j = element[1]\n",
    "        if( i < rows and j < cols and i >= 0 and j >= 0  ):\n",
    "            if( imag[i,j] == 0  and ([i,j] not in list_blackdots) ):\n",
    "                list_blackdots.append([i,j])\n",
    "                list_elements.extend([[i-1,j-1], [i-1,j], [i-1,j+1], [i,j-1], [i,j+1], [i+1,j-1], [i+1,j], [i+1,j+1]])\n",
    "    return list_blackdots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4752849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_near_dots( imag, black_dots ):\n",
    "    rows, cols = imag.shape\n",
    "    list_near_dots = []\n",
    "    search_x_y_operations = [[-1,-1], [-1,0], [-1,+1], [0,-1], [0,+1], [+1,-1], [+1,0],[+1,+1]]\n",
    "    if len(black_dots) != 0:\n",
    "        for dot in black_dots:\n",
    "            i = dot[0]\n",
    "            j = dot[1]\n",
    "            for operation in search_x_y_operations:\n",
    "                operation_x = operation[0]\n",
    "                operation_y = operation[1]\n",
    "                aux_i = i+operation_x\n",
    "                aux_j = j+operation_y\n",
    "                if( (aux_i < rows and aux_j < cols and aux_i >= 0 and aux_j >= 0) ):\n",
    "                    if ( imag[aux_i,aux_j] != 0  and ([aux_i,aux_j] not in list_near_dots) and ([aux_i,aux_j] not in black_dots) ):\n",
    "                        list_near_dots.append( [aux_i,aux_j] )\n",
    "                        \n",
    "    return list_near_dots\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4604fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dots_from_background( imag, i, j ):\n",
    "    rows, cols = imag.shape\n",
    "    list_near_pixels = []    \n",
    "    search_x_y_operations = [[-1,-1], [-1,0], [-1,+1], [0,-1], [0,+1], [+1,-1], [+1,0],[+1,+1]]\n",
    "    for operation in search_x_y_operations:\n",
    "        operation_x = operation[0]\n",
    "        operation_y = operation[1]\n",
    "        aux_i = i+operation_x\n",
    "        aux_j = j+operation_y    \n",
    "        if( (aux_i < rows and aux_j < cols and aux_i >= 0 and aux_j >= 0) ):\n",
    "            if ( imag[aux_i,aux_j] != 0  and (imag[aux_i,aux_j] not in list_near_pixels) ):\n",
    "                list_near_pixels.append( imag[aux_i,aux_j] )    \n",
    "    return list_near_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "891af04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_random_pixels( imag, pixels ):\n",
    "    rows, cols = imag.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            pixel = random.choice(pixels)\n",
    "            imag[i,j] = pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "478b7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_under_bigger( arr ):\n",
    "    bigger = max(arr)\n",
    "    for element in arr:\n",
    "        if ( element+30 < bigger ):\n",
    "            arr.remove(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e1df4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_black_corners( original_data_path, dest_path ):\n",
    "    create_folder('pre-process', dest_path)\n",
    "    all_images_paths = os.listdir(original_data_path)\n",
    "    for image_name in all_images_paths:\n",
    "        \n",
    "        img = cv2.imread(original_data_path+image_name)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        rows,cols = img_gray.shape\n",
    "        \n",
    "        corners = [[0,0], [rows-1, 0], [0, cols-1], [rows-1, cols-1]]\n",
    "\n",
    "        for corner in corners:\n",
    "            base = np.zeros([rows,cols],dtype=np.uint8)\n",
    "            i = corner[0]\n",
    "            j = corner[1]\n",
    "            pixels_black_dots = get_black_dots( img_gray, i, j)\n",
    "\n",
    "            if len(pixels_black_dots) != 0:\n",
    "    \n",
    "                pixels_near_dots = get_near_dots( img_gray, pixels_black_dots )\n",
    "                pixels_near_dots_layer_1 = get_near_dots( img_gray, pixels_near_dots )\n",
    "                pixels_near_dots_layer_2 = get_near_dots( img_gray, pixels_near_dots_layer_1 )\n",
    "                \n",
    "                dots_from_background = get_near_dots( img_gray, pixels_near_dots_layer_2 )\n",
    "                pixels_from_background = []\n",
    "                \n",
    "                for dot in dots_from_background:\n",
    "                    i = dot[0]\n",
    "                    j = dot[1]\n",
    "                    pixel = img_gray[i,j]\n",
    "                    pixels_from_background.append(pixel)\n",
    "                    \n",
    "                remove_under_bigger( pixels_from_background )\n",
    "                \n",
    "                common_pixels = get_most_common_values( pixels_from_background )\n",
    "                fill_with_random_pixels( base, common_pixels )\n",
    "\n",
    "                fill_with_white_pixels(img_gray, pixels_black_dots)\n",
    "                fill_with_white_pixels(img_gray, pixels_near_dots)\n",
    "                fill_with_white_pixels(img_gray, pixels_near_dots_layer_1)\n",
    "                fill_with_white_pixels(img_gray, pixels_near_dots_layer_2)\n",
    "\n",
    "                mask1_image = (img_gray < 255)\n",
    "                mask2_image = (img_gray == 255)\n",
    "\n",
    "                image_1 = img_gray *mask1_image\n",
    "                image_2 = base *mask2_image\n",
    "\n",
    "                img_gray = image_1+ image_2\n",
    "\n",
    "        cv2.imwrite(dest_path+'/pre-process/'+image_name, img_gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de842125",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/home/mcoronado/Escritorio/Codigo-Memoria/'\n",
    "remove_black_corners( main_path+'Data-set/Partial-Agreement-Images/', main_path+'Data-set' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9131b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae771476",
   "metadata": {},
   "source": [
    "# 4. TECNICA DE AUMENTO DE DATOS: RANDAUGMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e59277c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODIGO DE https://github.com/ildoonet/pytorch-randaugment/blob/master/RandAugment/augmentations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b5f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e5253df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_image( image, size ):\n",
    "    rows, cols = image.size\n",
    "    nrows, ncols = rows+size*2, cols+size*2\n",
    "    base = np.zeros([nrows,ncols],dtype=np.uint8)\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            base[i,j] = 254\n",
    "            \n",
    "    # copy image\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            base[i+size,j+size] = image.getpixel((j,i))\n",
    "            \n",
    "    # face 1\n",
    "    for i in range(size):\n",
    "        for j in range(cols):   \n",
    "            base[size+j, size-i-1] = image.getpixel((i,j))\n",
    "            \n",
    "    # face 2\n",
    "    for i in range(rows):\n",
    "        for j in range(size):   \n",
    "            base[size-j-1, size+i] = image.getpixel((i,j))    \n",
    "    \n",
    "    # face 3\n",
    "    for i in range(rows-size ,rows):\n",
    "        for j in range(cols):   \n",
    "            base[size+j, size-i+2*rows-1] = image.getpixel((i,j))  \n",
    "\n",
    "    # face 4\n",
    "    for i in range(rows):\n",
    "        for j in range(cols-size, cols):   \n",
    "            base[size-j+2*cols-1, size+i] = image.getpixel((i,j))\n",
    "    final = Image.fromarray(base)\n",
    "    return final  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d646d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranslateX(img, v): \n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    v = v * img.size[0]\n",
    "\n",
    "    o_w, o_h = img.size\n",
    "    img = extend_image( img , 10 )\n",
    "    \n",
    "    w, h = img.size\n",
    "    left = (w - o_w)/2\n",
    "    top = (h - o_h)/2\n",
    "    right = (w + o_w)/2\n",
    "    bottom = (h + o_h)/2    \n",
    "    \n",
    "    \n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0)).crop((left, top, right, bottom))\n",
    "\n",
    "\n",
    "def TranslateY(img, v): \n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    v = v * img.size[1]\n",
    "    \n",
    "    o_w, o_h = img.size\n",
    "    img = extend_image( img , 10 )\n",
    "    \n",
    "    w, h = img.size\n",
    "    left = (w - o_w)/2\n",
    "    top = (h - o_h)/2\n",
    "    right = (w + o_w)/2\n",
    "    bottom = (h + o_h)/2\n",
    "    \n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v)).crop((left, top, right, bottom))\n",
    "\n",
    "\n",
    "def Rotate(img, v):\n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    o_w, o_h = img.size\n",
    "    img = extend_image( img , 10 )\n",
    "    \n",
    "    w, h = img.size\n",
    "    left = (w - o_w)/2\n",
    "    top = (h - o_h)/2\n",
    "    right = (w + o_w)/2\n",
    "    bottom = (h + o_h)/2\n",
    "    \n",
    "    return img.rotate(v, resample=Image.BILINEAR).crop((left, top, right, bottom))\n",
    "\n",
    "\n",
    "def AutoContrast(img, _):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Invert(img, _):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Flip(img, _): \n",
    "    return PIL.ImageOps.flip(img)\n",
    "\n",
    "\n",
    "def Solarize(img, v): \n",
    "    return PIL.ImageOps.solarize(img, v)\n",
    "\n",
    "def Posterize(img, v):\n",
    "    v = int(v)\n",
    "    v = max(1, v)\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Contrast(img, v):\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def Brightness(img, v):\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v):\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Identity(img, v):\n",
    "    return img\n",
    "\n",
    "\n",
    "def is_x_in_list( x, arr ):\n",
    "    for element in arr:\n",
    "        if element == x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_n_random_elements( arr, n):\n",
    "    if len(arr) >= n:\n",
    "        out_arr = []\n",
    "        while len(out_arr) != n:\n",
    "            element = random.choice(arr)\n",
    "            if not( is_x_in_list( element, out_arr ) ):\n",
    "                out_arr.append(element)\n",
    "        return out_arr\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def augment_list():\n",
    "    l = [\n",
    "        (TranslateX, 0., 0.07),\n",
    "        (TranslateY, 0., 0.1),\n",
    "        (Rotate, 0, 25),\n",
    "        (AutoContrast, 0, 1),\n",
    "        (Invert, 0, 1),\n",
    "        (Flip, 0, 1),\n",
    "        (Solarize, 0, 256),\n",
    "        (Contrast, 0.3, 2),\n",
    "        (Brightness, 0.3, 1),\n",
    "        (Sharpness, 0.1, 2),\n",
    "    ]\n",
    "    return l\n",
    "\n",
    "\n",
    "class RandAugment:\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m      \n",
    "        self.augment_list = augment_list()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        ops = get_n_random_elements( self.augment_list, n=self.n )\n",
    "        for op, minval, maxval in ops:\n",
    "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
    "            img = op(img, val)\n",
    "\n",
    "        return img, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab8dfb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def augment_randAugment_SCIAN(dir_data, n, m): \n",
    "    classes_names = ['01-Normal', '02-Tapered', '03-Pyriform', '04-Small', '05-Amorphous']\n",
    "    class_name = '01-Normal'\n",
    "    dir_class = dir_data+'/'+class_name\n",
    "    images_names = os.listdir(dir_class)\n",
    "    \n",
    "    transform_list = []\n",
    "    \n",
    "    if os.path.exists(dir_class+'/randAugment'):\n",
    "        shutil.rmtree(dir_class+'/randAugment')   \n",
    "    os.mkdir(dir_class+'/randAugment')        \n",
    "    for image_name in images_names:\n",
    "        element = []\n",
    "        element.append(image_name)\n",
    "        if random.random() > 0.5:\n",
    "            dir_image = dir_class+'/'+image_name\n",
    "            if dir_image.endswith('tif'):\n",
    "                image = Image.open(dir_image,mode='r')\n",
    "                rand = RandAugment(n,m)\n",
    "                augmented_image, ops = rand(image)\n",
    "                element.append( ops )\n",
    "                transform_list.append( element )\n",
    "                augmented_image.save(dir_class+'/randAugment/rand-'+image_name)\n",
    "    return transform_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a543d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/ipykernel_launcher.py:33: DeprecationWarning: AFFINE is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.AFFINE instead.\n",
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/ipykernel_launcher.py:48: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: AFFINE is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transform.AFFINE instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dir_train = '/home/mcoronado/Escritorio/Codigo-Memoria/Data-set/data/train'\n",
    "\n",
    "\n",
    "# 10 x 30\n",
    "\n",
    "transform_list = augment_randAugment_SCIAN(dir_train,5,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6be410c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = 'ch00_p1-pl2-sample3-sperm7.tif'\n",
    "\n",
    "for element in transform_list:\n",
    "    image_name = element[0]\n",
    "    if image_name == search:\n",
    "        image_ops = element[1]\n",
    "        for op in image_ops:\n",
    "            print('/n')\n",
    "            print(op[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af6d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a070b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86c38af3",
   "metadata": {},
   "source": [
    "# 5. TECNICA DE AUMENTO DE DATOS: GRIDMASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf2e46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid(object):\n",
    "    def __init__(self, d1, d2, rotate = 1, ratio = 0.5, mode=0, prob=1.):\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "        self.rotate = rotate\n",
    "        self.ratio = ratio\n",
    "        self.mode=mode\n",
    "        self.st_prob = self.prob = prob\n",
    "\n",
    "    def set_prob(self, epoch, max_epoch):\n",
    "        self.prob = self.st_prob * min(1, epoch / max_epoch)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        convert_tensor = transforms.ToTensor()\n",
    "        convert_PIL = transforms.ToPILImage()\n",
    "        img = convert_tensor(img)\n",
    "        if np.random.rand() > self.prob:\n",
    "            return img\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)  \n",
    "        # 1.5 * h, 1.5 * w works fine with the squared images\n",
    "        # But with rectangular input, the mask might not be able to recover back to the input image shape\n",
    "        # A square mask with edge length equal to the diagnoal of the input image \n",
    "        # will be able to cover all the image spot after the rotation. This is also the minimum square.\n",
    "        hh = math.ceil((math.sqrt(h*h + w*w)))\n",
    "        \n",
    "        d = np.random.randint(self.d1, self.d2)\n",
    "        #d = self.d\n",
    "        \n",
    "        # maybe use ceil? but i guess no big difference\n",
    "        self.l = math.ceil(d*self.ratio)\n",
    "        \n",
    "        mask = np.ones((hh, hh), np.float32)\n",
    "        st_h = np.random.randint(d)\n",
    "        st_w = np.random.randint(d)\n",
    "        for i in range(-1, hh//d+1):\n",
    "                s = d*i + st_h\n",
    "                t = s+self.l\n",
    "                s = max(min(s, hh), 0)\n",
    "                t = max(min(t, hh), 0)\n",
    "                mask[s:t,:] *= 0\n",
    "        for i in range(-1, hh//d+1):\n",
    "                s = d*i + st_w\n",
    "                t = s+self.l\n",
    "                s = max(min(s, hh), 0)\n",
    "                t = max(min(t, hh), 0)\n",
    "                mask[:,s:t] *= 0\n",
    "        r = np.random.randint(self.rotate)\n",
    "        mask = Image.fromarray(np.uint8(mask))\n",
    "        mask = mask.rotate(r)\n",
    "        mask = np.asarray(mask)\n",
    "        mask = mask[(hh-h)//2:(hh-h)//2+h, (hh-w)//2:(hh-w)//2+w]\n",
    "\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        if self.mode == 1:\n",
    "            mask = 1-mask\n",
    "\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask \n",
    "        \n",
    "        img = convert_PIL(img)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb069f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf01c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058c625b",
   "metadata": {},
   "source": [
    "# 6. TECNICA DE AUMENTO DE DATOS: SMOOTHMIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a40b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30326e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46d893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35178f7b",
   "metadata": {},
   "source": [
    "# BLOQUE PRINCIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d24b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/home/mcoronado/Escritorio/Codigo-Memoria/'\n",
    "raw_dataset_name = 'raw_data'\n",
    "dataset_name = 'data'\n",
    "\n",
    "\n",
    "test_porcentage = 0.3\n",
    "valid_porcentage = 0.7*0.2\n",
    "train_porcentage = 0.7*0.8\n",
    "\n",
    "image_dimention = (35,35)\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "epochs = 15\n",
    "\n",
    "remove_black_corners( main_path+'Data-set/Partial-Agreement-Images/', main_path+'Data-set' )\n",
    "#pre_process_dataset_name = 'pre-process'\n",
    "\n",
    "create_dataset(path_expertAnotations = main_path+'Data-set/PA-expert-annotations.txt', \n",
    "              path_partialImages = main_path+'Data-set/'+pre_process_dataset_name+'/',\n",
    "              dest_path = main_path+'Data-set',\n",
    "              dataset_name = raw_dataset_name)\n",
    "\n",
    "\n",
    "\n",
    "create_train_valid_test(origin_path=main_path+'Data-set/'+raw_dataset_name,\n",
    "                        dest_path=main_path+'Data-set/',\n",
    "                        dataset_name = dataset_name,\n",
    "                        porcentages = [test_porcentage,valid_porcentage,train_porcentage])\n",
    "\n",
    "dataset_path = main_path+'Data-set/'+dataset_name\n",
    "\n",
    "trainloader, validloader, testloader = load_data_pytorch_format( dataset_path, batch_size, image_dimention)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad789d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/mcoronado/anaconda3/envs/python3-7/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "Bad file descriptor (src/signaler.cpp:184)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 19150) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 19150) is killed by signal: Aborted. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18904/3541346418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_init\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Model here is the model that you have created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprocess_net\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18904/280611250.py\u001b[0m in \u001b[0;36mprocess_net\u001b[0;34m(net, epochs, trainloader, validloader, testloader, optimizer, criterion, model_save_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18904/2262134592.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunning_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcount_minibatchs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3-7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 19150) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "#net = models.resnet34()\n",
    "#net = models.resnet50()\n",
    "#net = models.vgg19()\n",
    "#net = models.densenet161()\n",
    "#net = models.densenet169()\n",
    "\n",
    "net = models.resnet18()\n",
    "model_name = 'resnet18_random_v2'\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_path = main_path+'outputs/'+model_name\n",
    "create_folder_wremoving('outputs', main_path)\n",
    "create_folder_wremoving(model_name, main_path+'outputs/')\n",
    "\n",
    "net.apply(random_init) #Model here is the model that you have created\n",
    "\n",
    "process_net( net , epochs, trainloader, validloader, testloader, optimizer, criterion, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b11fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb51eebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da9fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e785f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa58a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f28341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee5254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f014e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db543a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_path = '/home/mcoronado/Escritorio/Codigo-Memoria/'\n",
    "remove_black_corners( main_path+'Data-set/Partial-Agreement-Images/', main_path+'Data-set' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc63e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d68c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
